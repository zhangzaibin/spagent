# ğŸ“Œ Introduction

This repository provides **SPAgent** - a flexible and modular **Spatial Intelligence Agent** that integrates **agentic skills** into **multi-modal understanding** using external expert models and LLMs.

## ğŸ†• **New SPAgent Architecture (v2.0)**

**SPAgent** replaces the old workflow system with a modern, modular architecture:

- âœ… **Modular Tool System** - Mix and match any combination of expert tools
- âœ… **Dynamic Tool Management** - Add/remove tools at runtime
- âœ… **Parallel Tool Execution** - Automatic concurrent processing when possible
- âœ… **Multi-Image Analysis** - Handle single or multiple images seamlessly
- âœ… **Multiple Model Support** - GPT, Qwen, and local VLLM models
- âœ… **Flexible Configuration** - Easy to customize and extend

---

## ğŸ“‚ Project Structure

| Module | Path | Description |
|--------|------|-------------|
| **SPAgent Core** | `spagent/core/` | ğŸ†• Main agent architecture:<br>- SPAgent class<br>- Tool base classes<br>- Model wrappers<br>- Unified prompt system |
| **Tools** | `spagent/tools/` | ğŸ†• Modular expert tools:<br>- DepthEstimationTool<br>- SegmentationTool<br>- ObjectDetectionTool<br>- SupervisionTool<br>- YOLOETool |
| **Models** | `spagent/models/` | ğŸ†• Model wrappers:<br>- GPTModel<br>- QwenModel<br>- QwenVLLMModel |
| **External Experts** | `spagent/external_experts/` | Specialized models for spatial intelligence:<br>- Depth Estimation (**Depth-AnythingV2**)<br>- Object Detection & Segmentation (**SAM2**)<br>- Open-vocabulary Detection (**GroundingDINO**)<br>- 3D Reconstruction (**Pi3**)<br>- Can run as external APIs |
| **VLLM Models** | `spagent/vllm_models/` | VLLM inference functions & wrappers:<br>- GPT / QwenVL inference<br>- Model loading & serving utilities<br>- Unified API for LLM calls |
| **Examples** | `spagent/examples/` | Example scripts and usage tutorials |
| **Legacy Workflows** | `spagent/workflows/` | âš ï¸ **Deprecated** - Old workflow system |

---

## ğŸš€ Quick Start

### 1. åŸºç¡€ä½¿ç”¨ (Basic Usage)

```python
from spagent import SPAgent
from spagent.models import GPTModel
from spagent.tools import DepthEstimationTool, SegmentationTool

# åˆ›å»ºæ¨¡å‹å’Œå·¥å…·
model = GPTModel(model_name="gpt-4o-mini")
tools = [
    DepthEstimationTool(use_mock=True),    # æ·±åº¦ä¼°è®¡
    SegmentationTool(use_mock=True)        # å›¾åƒåˆ†å‰²
]

# åˆ›å»ºæ™ºèƒ½ä½“
agent = SPAgent(model=model, tools=tools)

# è§£å†³é—®é¢˜
result = agent.solve_problem("image.jpg", "åˆ†æè¿™å¼ å›¾ç‰‡çš„æ·±åº¦å…³ç³»å’Œä¸»è¦å¯¹è±¡")
print(result['answer'])
```

### 2. æ··åˆå¤šå·¥å…·ä½¿ç”¨ (Multi-Tool Usage)

```python
from spagent import SPAgent
from spagent.models import GPTModel
from spagent.tools import (
    DepthEstimationTool,      # æ·±åº¦ä¼°è®¡
    SegmentationTool,         # å›¾åƒåˆ†å‰²  
    ObjectDetectionTool,      # ç›®æ ‡æ£€æµ‹
    SupervisionTool,          # ç›‘ç£å­¦ä¹ å·¥å…·
    YOLOETool                 # YOLO-Eæ£€æµ‹
)

# åˆ›å»ºå…¨åŠŸèƒ½æ™ºèƒ½ä½“
model = GPTModel(model_name="gpt-4o-mini")
tools = [
    DepthEstimationTool(use_mock=True),
    SegmentationTool(use_mock=True),
    ObjectDetectionTool(use_mock=True),
    SupervisionTool(use_mock=True),
    YOLOETool(use_mock=True)
]

agent = SPAgent(model=model, tools=tools, max_workers=4)

# å¤æ‚é—®é¢˜åˆ†æ
result = agent.solve_problem(
    "image.jpg", 
    "å…¨é¢åˆ†æè¿™å¼ å›¾ç‰‡ï¼šè¯†åˆ«æ‰€æœ‰å¯¹è±¡ï¼Œåˆ†ææ·±åº¦å…³ç³»ï¼Œå¹¶åˆ†å‰²é‡è¦åŒºåŸŸ"
)

print(f"ç­”æ¡ˆ: {result['answer']}")
print(f"ä½¿ç”¨çš„å·¥å…·: {result['used_tools']}")
print(f"ç”Ÿæˆçš„é¢å¤–å›¾åƒ: {result['additional_images']}")
```

### 3. åŠ¨æ€å·¥å…·ç®¡ç† (Dynamic Tool Management)

```python
# ä»åŸºç¡€æ™ºèƒ½ä½“å¼€å§‹
agent = SPAgent(model=GPTModel())

# åŠ¨æ€æ·»åŠ å·¥å…·
agent.add_tool(DepthEstimationTool(use_mock=True))
agent.add_tool(SegmentationTool(use_mock=True))

# æŸ¥çœ‹å½“å‰å·¥å…·
print(f"å½“å‰å·¥å…·: {agent.list_tools()}")

# ç§»é™¤ä¸éœ€è¦çš„å·¥å…·
agent.remove_tool("depth_estimation_tool")

# æ›´æ¢æ¨¡å‹
from spagent.models import QwenModel
agent.set_model(QwenModel(model_name="qwen2.5-vl-7b-instruct"))
```

### 4. å¤šå›¾åƒåˆ†æ (Multi-Image Analysis)

```python
# åˆ†æå¤šå¼ å›¾åƒ
image_paths = ["image1.jpg", "image2.jpg", "image3.jpg"]
result = agent.solve_problem(
    image_paths, 
    "æ¯”è¾ƒè¿™äº›å›¾åƒçš„å·®å¼‚ï¼Œåˆ†ææ·±åº¦å˜åŒ–å’Œå¯¹è±¡åˆ†å¸ƒ"
)
```

---
### 5. å›¾åƒæ•°æ®é›†è¯„æµ‹ (Image Dataset Evaluation)

æœ¬èŠ‚ä»‹ç»å¦‚ä½•åœ¨å›¾åƒæ•°æ®é›†ä¸Šè¯„æµ‹SPAgentçš„æ€§èƒ½ã€‚æ‰€æœ‰æ•°æ®é›†éƒ½éœ€è¦å…ˆä¸‹è½½å¹¶è½¬æ¢ä¸ºç»Ÿä¸€çš„JSONLæ ¼å¼ï¼Œå…¶ä¸­æ¯æ¡æ•°æ®åŒ…å«ä»¥ä¸‹æ ‡å‡†å­—æ®µï¼š
- `id`: æ•°æ®æ ·æœ¬çš„å”¯ä¸€æ ‡è¯†ç¬¦
- `image`: å›¾ç‰‡è·¯å¾„åˆ—è¡¨ï¼ˆæ”¯æŒå¤šå›¾åƒï¼‰ï¼Œè‹¥æ²¡æœ‰åˆ™ä¸ºç©º
- `video`ï¼šè§†é¢‘è·¯å¾„åˆ—è¡¨ï¼Œè‹¥æ²¡æœ‰åˆ™ä¸ºç©º
- `conversations`: å¯¹è¯æ ¼å¼çš„é—®ç­”å†…å®¹ï¼Œéœ€åŒ…å«é—®é¢˜é€‰é¡¹å’Œç­”æ¡ˆï¼Œå¦‚ï¼ˆ"conversations": [{"from": "human", "value": "{question}\nSelect from the following choices. (A) .. A (B) .."},{"from": "gpt", "value": "A"}],ï¼‰
- `task`: ä»»åŠ¡ç±»å‹ï¼ˆå¦‚Object_Localization, Depth, Countç­‰ï¼‰
- `input_type`: è¾“å…¥ç±»å‹ï¼ˆé€šå¸¸ä¸º"Image"ï¼‰
- `output_type`: è¾“å‡ºç±»å‹ï¼ˆå¦‚"MCQ"è¡¨ç¤ºå¤šé€‰é¢˜ï¼‰
- `data_source`: æ•°æ®é›†æ¥æº

#### 1. BLINKæ•°æ®é›†

```bash
# ä¸‹è½½BLINKæ•°æ®é›†å¹¶è½¬æ¢ä¸ºJSONLæ ¼å¼
python spagent/utils/download_blink.py

# è¿è¡Œè¯„æµ‹
python evaluate_img.py --data_path dataset/BLINK_All_Tasks.jsonl --max_workers 4 --image_base_path dataset --model gpt-4o-mini
```

#### 2. CVBenchæ•°æ®é›†
CVBenchä¸“æ³¨äºè®¡ç®—æœºè§†è§‰çš„åŸºç¡€èƒ½åŠ›æµ‹è¯•ï¼ŒåŒ…æ‹¬æ·±åº¦ä¼°è®¡ã€ç›®æ ‡è®¡æ•°ã€ç©ºé—´å…³ç³»ç­‰ä»»åŠ¡ã€‚

```bash
# ç¬¬ä¸€æ­¥ï¼šä¸‹è½½CVBenchå›¾ç‰‡ï¼ˆéœ€è¦å…ˆä¿å­˜parquetæ–‡ä»¶åˆ°datasetç›®å½•ï¼‰
# æ•°æ®é›†åœ°å€ï¼šhttps://huggingface.co/datasets/nyu-visionx/CV-Bench
python spagent/utils/cvbench_img.py --subset both --root dataset --out dataset/CVBench

# ç¬¬äºŒæ­¥ï¼šè½¬æ¢ä¸ºJSONLæ ¼å¼
python spagent/utils/download_cvbench.py

# ç¬¬ä¸‰æ­¥ï¼šåˆ›å»ºæ ·æœ¬æ•°æ®ï¼ˆå¯é€‰ï¼Œç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
python dataset/create_cvbench_sample.py

# è¿è¡Œè¯„æµ‹
python evaluate_img.py --data_path dataset/cvbench_data.jsonl --max_samples 30 --max_workers 4 --image_base_path dataset --model gpt-4o-mini
```

## ğŸ› ï¸ å®‰è£…å’Œé…ç½® (Installation & Setup)

### 1. ç¯å¢ƒå‡†å¤‡ (Environment Setup)

```bash
# åˆ›å»ºPython 3.11ç¯å¢ƒ (å…¶ä»–ç‰ˆæœ¬å¯èƒ½æœ‰å…¼å®¹æ€§é—®é¢˜)
conda create -n spagent python=3.11
conda activate spagent

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
pip install "httpx[socks]"
```

### 2. APIé…ç½® (API Configuration)

```bash
# OpenAI API
export OPENAI_API_KEY="your_api_key"
export OPENAI_BASE_URL="http://35.220.164.252:3888/v1/"

# Qwen API (ç”³è¯·åœ°å€: https://bailian.console.aliyun.com)
export DASHSCOPE_API_KEY="your_api_key"

# moondream APIï¼ˆç”³è¯·åœ°å€ï¼šhttps://moondream.aiï¼‰
export MOONDREAM_API_KEY="your_api_key"

# æµ‹è¯•APIè¿æ¥
python spagent/vllm_models/qwen.py
```

### 3. ä¸‹è½½æ¨¡å‹æƒé‡ (Download Model Weights)

åˆ›å»ºcheckpointsç›®å½•ï¼š
```bash
mkdir -p checkpoints/{grounding_dino,depth_anything,pi3,sam2}
```

#### Depth-Anything V2 (æ·±åº¦ä¼°è®¡)
```bash
# é€‰æ‹©ä¸€ä¸ªæ¨¡å‹ (æ¨èBaseç‰ˆæœ¬)
cd checkpoints/depth_anything

# Small (~25MB, æœ€å¿«)
wget https://huggingface.co/depth-anything/Depth-Anything-V2-Small/resolve/main/depth_anything_v2_vits.pth

# Base (~100MB, å¹³è¡¡) - æ¨è
wget https://huggingface.co/depth-anything/Depth-Anything-V2-Base/resolve/main/depth_anything_v2_vitb.pth

# Large (~350MB, æœ€é«˜è´¨é‡)
wget https://huggingface.co/depth-anything/Depth-Anything-V2-Large/resolve/main/depth_anything_v2_vitl.pth
```

#### SAM2 (å›¾åƒåˆ†å‰²)
```bash
cd checkpoints/sam2

# è‡ªåŠ¨ä¸‹è½½æ‰€æœ‰æ¨¡å‹
wget https://raw.githubusercontent.com/facebookresearch/sam2/main/checkpoints/download_ckpts.sh
chmod +x download_ckpts.sh
./download_ckpts.sh

# æˆ–æ‰‹åŠ¨ä¸‹è½½æ¨èæ¨¡å‹
wget https://dl.fbaipublicfiles.com/segment_anything_2/092824/sam2.1_hiera_base_plus.pt
```

#### GroundingDINO (ç›®æ ‡æ£€æµ‹)
```bash
cd checkpoints/grounding_dino
wget https://github.com/IDEA-Research/GroundingDINO/releases/download/v0.1.0-alpha2/groundingdino_swinb_cogcoor.pth

```

### 4. éƒ¨ç½²å¤–éƒ¨ä¸“å®¶æœåŠ¡ (Deploy External Expert Services)

å¦‚æœè¦ä½¿ç”¨çœŸå®çš„ä¸“å®¶æœåŠ¡è€Œémockæ¨¡å¼ï¼š

```bash
# éœ€è¦GPUå†…å­˜ >= 24G
apt-get install tmux

# éƒ¨ç½²æ·±åº¦ä¼°è®¡æœåŠ¡
python spagent/external_experts/Depth_AnythingV2/depth_server.py \
  --checkpoint_path checkpoints/depth_anything/depth_anything_v2_vitb.pth \
  --port 20019

# éƒ¨ç½²SAM2åˆ†å‰²æœåŠ¡ï¼Œè¿™é‡Œé¢éœ€è¦å°†samçš„æƒé‡åå­—renameæˆsam2.1_b.ptï¼Œå¦åˆ™ä¼šæŠ¥é”™
python spagent/external_experts/SAM2/sam2_server.py \
  --checkpoint_path checkpoints/sam2/sam2.1_b.pt \
  --port 20020


# éƒ¨ç½²grounding dino
# sometimes the network cannot connect the huggingface, we can reset the huggingfacesource
export HF_ENDPOINT=https://hf-mirror.com

python spagent/external_experts/GroundingDINO/grounding_dino_server.py \
  --model_path checkpoints/grounding_dino/groundingdino_swinb_cogcoor.pth \
  --port 20022

# éƒ¨ç½²moondream
python spagent/external_experts/GroundingDINO/grounding_dino_server.py 
  --port 20024
```

---

## ğŸ¯ è¿è¡Œç¤ºä¾‹ (Run Examples)

### æ–°SPAgentç¤ºä¾‹ (New SPAgent Examples)

```bash
cd spagent

# åŸºç¡€SPAgentä½¿ç”¨ç¤ºä¾‹
python examples/spagent_example.py assets/example.png "åˆ†æè¿™å¼ å›¾ç‰‡"

# ä½¿ç”¨çœŸå®å›¾ç‰‡æµ‹è¯•
python examples/spagent_example.py your_image.jpg "æè¿°å›¾ç‰‡ä¸­çš„å¯¹è±¡å’Œæ·±åº¦å…³ç³»"
```

### å·¥å…·å®šä¹‰ç¤ºä¾‹ (Tool Definition Examples)

#### 1. æ·±åº¦åˆ†æä¸“ç”¨æ™ºèƒ½ä½“
```python
from spagent import SPAgent
from spagent.models import GPTModel
from spagent.tools import DepthEstimationTool, SegmentationTool

# ä¸“æ³¨æ·±åº¦åˆ†æçš„æ™ºèƒ½ä½“
model = GPTModel(model_name="gpt-4o-mini")
depth_tools = [
    DepthEstimationTool(use_mock=True),
    SegmentationTool(use_mock=True)  # è¾…åŠ©åˆ†å‰²
]

depth_agent = SPAgent(model=model, tools=depth_tools)
result = depth_agent.solve_problem(
    "image.jpg", 
    "åˆ†æå›¾ç‰‡çš„æ·±åº¦åˆ†å¸ƒï¼Œå“ªäº›ç‰©ä½“ç¦»ç›¸æœºè¿‘ï¼Œå“ªäº›è¿œï¼Ÿ"
)
```

#### 2. ç›®æ ‡æ£€æµ‹ä¸“ç”¨æ™ºèƒ½ä½“
```python
from spagent.tools import ObjectDetectionTool, SupervisionTool, YOLOETool

# ä¸“æ³¨ç›®æ ‡æ£€æµ‹çš„æ™ºèƒ½ä½“
detection_tools = [
    ObjectDetectionTool(use_mock=True),
    SupervisionTool(use_mock=True),
    YOLOETool(use_mock=True),
    SegmentationTool(use_mock=True)  # è¾…åŠ©åˆ†å‰²
]

detection_agent = SPAgent(model=model, tools=detection_tools)
result = detection_agent.solve_problem(
    "image.jpg", 
    "æ£€æµ‹å¹¶è¯†åˆ«å›¾ç‰‡ä¸­çš„æ‰€æœ‰å¯¹è±¡ï¼ŒåŒ…æ‹¬ä½ç½®å’Œç±»å‹"
)
```

#### 3. è‡ªå®šä¹‰å·¥å…·ç»„åˆ
```python
# åˆ›å»ºç©ºæ™ºèƒ½ä½“ï¼Œé€æ­¥æ·»åŠ å·¥å…·
agent = SPAgent(model=GPTModel())

# æ ¹æ®éœ€è¦æ·»åŠ å·¥å…·
if need_depth:
    agent.add_tool(DepthEstimationTool(use_mock=True))

if need_detection:
    agent.add_tool(ObjectDetectionTool(use_mock=True))
    
if need_segmentation:
    agent.add_tool(SegmentationTool(use_mock=True))

# ä½¿ç”¨é…ç½®å¥½çš„æ™ºèƒ½ä½“
result = agent.solve_problem("image.jpg", "æ ¹æ®å¯ç”¨å·¥å…·åˆ†æå›¾ç‰‡")
```

---

## ğŸ”§ å·¥å…·æ··åˆç­–ç•¥ (Tool Mixing Strategies)

### 1. å¹¶è¡Œå·¥å…·æ‰§è¡Œ (Parallel Tool Execution)
SPAgentä¼šè‡ªåŠ¨æ£€æµ‹å¯ä»¥å¹¶è¡Œæ‰§è¡Œçš„å·¥å…·ï¼š

```python
# è¿™ä¸ªé—®é¢˜ä¼šè§¦å‘å¤šä¸ªå·¥å…·å¹¶è¡Œæ‰§è¡Œ
result = agent.solve_problem(
    "image.jpg",
    "åŒæ—¶è¿›è¡Œæ·±åº¦ä¼°è®¡ã€ç›®æ ‡æ£€æµ‹å’Œå›¾åƒåˆ†å‰²"  # ä¼šå¹¶è¡Œæ‰§è¡Œ3ä¸ªå·¥å…·
)
```

### 2. æ¡ä»¶å·¥å…·é€‰æ‹© (Conditional Tool Selection)
æ¨¡å‹ä¼šæ ¹æ®é—®é¢˜è‡ªåŠ¨é€‰æ‹©éœ€è¦çš„å·¥å…·ï¼š

```python
# åªä¼šä½¿ç”¨æ·±åº¦ç›¸å…³çš„å·¥å…·
result1 = agent.solve_problem("image.jpg", "åˆ†ææ·±åº¦å…³ç³»")

# åªä¼šä½¿ç”¨æ£€æµ‹ç›¸å…³çš„å·¥å…·  
result2 = agent.solve_problem("image.jpg", "æ£€æµ‹è½¦è¾†å’Œè¡Œäºº")

# ä¼šä½¿ç”¨å¤šç§å·¥å…·
result3 = agent.solve_problem("image.jpg", "å…¨é¢åˆ†æå›¾ç‰‡")
```

### 3. å·¥å…·é“¾ç»„åˆ (Tool Chain Combination)
```python
# å¤æ‚å·¥å…·é“¾ï¼šæ£€æµ‹ â†’ åˆ†å‰² â†’ æ·±åº¦åˆ†æ
result = agent.solve_problem(
    "image.jpg",
    """
    é¦–å…ˆæ£€æµ‹å›¾ç‰‡ä¸­çš„ä¸»è¦å¯¹è±¡ï¼Œ
    ç„¶åå¯¹æ£€æµ‹åˆ°çš„å¯¹è±¡è¿›è¡Œç²¾ç¡®åˆ†å‰²ï¼Œ
    æœ€ååˆ†æè¿™äº›å¯¹è±¡çš„æ·±åº¦å…³ç³»
    """
)
```

---

## ğŸ“– å¯ç”¨å·¥å…·åˆ—è¡¨ (Available Tools)

| å·¥å…·ç±» | åŠŸèƒ½ | ç”¨é€” | å‚æ•° |
|--------|------|------|------|
| `DepthEstimationTool` | æ·±åº¦ä¼°è®¡ | åˆ†æå›¾åƒçš„3Dæ·±åº¦å…³ç³» | `image_path` |
| `SegmentationTool` | å›¾åƒåˆ†å‰² | ç²¾ç¡®åˆ†å‰²å›¾åƒä¸­çš„å¯¹è±¡ | `image_path`, `point_coords`(å¯é€‰), `box`(å¯é€‰) |
| `ObjectDetectionTool` | ç›®æ ‡æ£€æµ‹ | åŸºäºæ–‡æœ¬æè¿°æ£€æµ‹å¯¹è±¡ | `image_path`, `text_prompt`, `box_threshold`, `text_threshold` |
| `SupervisionTool` | ç›‘ç£æ£€æµ‹ | é€šç”¨ç›®æ ‡æ£€æµ‹å’Œåˆ†å‰² | `image_path`, `task` ("image_det"æˆ–"image_seg") |
| `YOLOETool` | YOLO-Eæ£€æµ‹ | è‡ªå®šä¹‰ç±»åˆ«çš„é«˜ç²¾åº¦æ£€æµ‹ | `image_path`, `task`, `class_names` |

## ğŸ¤– å¯ç”¨æ¨¡å‹ (Available Models)

| æ¨¡å‹ç±» | æè¿° | æ¨èç”¨é€” |
|--------|------|----------|
| `GPTModel` | OpenAI GPTæ¨¡å‹ | é€šç”¨è§†è§‰ç†è§£ï¼Œæœ€ä½³æ•ˆæœ |
| `QwenModel` | é€šä¹‰åƒé—®VLæ¨¡å‹ | ä¸­æ–‡ç†è§£ä¼˜ç§€ |
| `QwenVLLMModel` | æœ¬åœ°éƒ¨ç½²çš„Qwen VLLM | æœ¬åœ°æ¨ç†ï¼Œä¿æŠ¤éšç§ |

---

## ğŸ“Š æ€§èƒ½ä¼˜åŠ¿ (Performance Benefits)

### æ–°æ¶æ„ vs æ—§Workflowç³»ç»Ÿ

| ç‰¹æ€§ | æ—§Workflow | æ–°SPAgent | æ”¹è¿› |
|------|------------|-----------|------|
| ä»£ç å¤ç”¨ | æ¯ä¸ªç»„åˆéœ€è¦å•ç‹¬çš„workflowç±» | å•ä¸€SPAgentç±»å¤„ç†æ‰€æœ‰ç»„åˆ | **90%ä»£ç å‡å°‘** |
| å·¥å…·ç»„åˆ | å›ºå®šç»„åˆï¼Œéš¾ä»¥ä¿®æ”¹ | ä»»æ„ç»„åˆï¼ŒåŠ¨æ€è°ƒæ•´ | **æ— é™çµæ´»æ€§** |
| å¹¶è¡Œæ‰§è¡Œ | ä¸²è¡Œæ‰§è¡Œå·¥å…· | è‡ªåŠ¨å¹¶è¡Œæ‰§è¡Œ | **3-5xæ€§èƒ½æå‡** |
| æ‰©å±•æ€§ | æ·»åŠ å·¥å…·éœ€è¦ä¿®æ”¹å¤šä¸ªç±» | æ·»åŠ å·¥å…·åªéœ€å®ç°Toolæ¥å£ | **æ˜“äºæ‰©å±•** |
| ç»´æŠ¤æ€§ | å¤§é‡é‡å¤ä»£ç  | æ¸…æ™°çš„æ¨¡å—åˆ†ç¦» | **æ˜“äºç»´æŠ¤** |

---

## ğŸ”„ ä»æ—§ç³»ç»Ÿè¿ç§» (Migration from Old System)

è¯¦ç»†è¿ç§»æŒ‡å—è¯·æŸ¥çœ‹ï¼š[MIGRATION_GUIDE.md](spagent/MIGRATION_GUIDE.md)

### å¿«é€Ÿè¿ç§»ç¤ºä¾‹ï¼š

**æ—§ä»£ç :**
```python
from workflows.mix_workflow import MixedExpertWorkflow
workflow = MixedExpertWorkflow(use_mock=True)
result = workflow.run_workflow("image.jpg", "åˆ†æå›¾ç‰‡")
```

**æ–°ä»£ç :**
```python
from spagent import SPAgent
from spagent.models import GPTModel
from spagent.tools import DepthEstimationTool, SegmentationTool, ObjectDetectionTool

model = GPTModel()
tools = [DepthEstimationTool(use_mock=True), SegmentationTool(use_mock=True), ObjectDetectionTool(use_mock=True)]
agent = SPAgent(model=model, tools=tools)
result = agent.solve_problem("image.jpg", "åˆ†æå›¾ç‰‡")
```

---

## ğŸ§ª æµ‹è¯•å’Œå¼€å‘ (Testing & Development)

### Mockæ¨¡å¼æµ‹è¯•
```python
# ä½¿ç”¨mockæ¨¡å¼è¿›è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆä¸éœ€è¦éƒ¨ç½²å®é™…æœåŠ¡ï¼‰
tools = [
    DepthEstimationTool(use_mock=True),
    SegmentationTool(use_mock=True),
    ObjectDetectionTool(use_mock=True)
]
```

### çœŸå®æœåŠ¡æ¨¡å¼
```python
# ä½¿ç”¨çœŸå®éƒ¨ç½²çš„æœåŠ¡
tools = [
    DepthEstimationTool(use_mock=False, server_url="http://localhost:20019"),
    SegmentationTool(use_mock=False, server_url="http://localhost:20020"),
    ObjectDetectionTool(use_mock=False, server_url="http://localhost:30969")
]
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹ (Important Notes)

1. **Pythonç‰ˆæœ¬**: å»ºè®®ä½¿ç”¨Python 3.11ï¼Œå…¶ä»–ç‰ˆæœ¬å¯èƒ½æœ‰å…¼å®¹æ€§é—®é¢˜
2. **å†…å­˜è¦æ±‚**: çœŸå®æ¨¡å¼éœ€è¦GPUå†…å­˜ >= 24GB
3. **ç½‘ç»œé…ç½®**: ç¡®ä¿APIå¯†é’¥å’ŒæœåŠ¡å™¨åœ°å€é…ç½®æ­£ç¡®
4. **å¹¶å‘æ§åˆ¶**: å¯é€šè¿‡`max_workers`å‚æ•°æ§åˆ¶å¹¶è¡Œå·¥å…·æ•°é‡

---

## ğŸ” External Experts
| å·¥å…·åç§° | ç±»å‹ | ä¸»è¦åŠŸèƒ½ | å¤‡æ³¨ |
| --- | --- | --- | --- |
| **Depth-AnythingV2** | 3D | å•ç›®æ·±åº¦ä¼°è®¡ | å°† 2D å›¾åƒè½¬ä¸ºåƒç´ çº§æ·±åº¦å›¾ |
| **SAM2** | 2D | å›¾åƒåˆ†å‰² | Segment Anything æ¨¡å‹ç¬¬äºŒä»£ï¼Œäº¤äº’å¼æˆ–è‡ªåŠ¨åˆ†å‰² |
| **Supervision** | 2D | è§†è§‰ä»»åŠ¡è¾…åŠ©å·¥å…·åº“ | ç”¨äºç›®æ ‡æ£€æµ‹ã€åˆ†å‰²ç»“æœå¯è§†åŒ–å’Œåå¤„ç† |
| **GroundingDINO** | 2D | æ–‡æœ¬é©±åŠ¨ç›®æ ‡æ£€æµ‹ | åŸºäºè‡ªç„¶è¯­è¨€è¿›è¡Œæ£€æµ‹å’Œæ¡†é€‰ |
| **Pi3** | 3D | ç‚¹äº‘ç”Ÿæˆä¸å¤„ç† | å°†å›¾åƒæˆ–å¤šè§†è§’è¾“å…¥è½¬ä¸º 3D è¡¨ç¤º |

## ğŸ“ˆ Future Roadmap

- [ ] æ”¯æŒæ›´å¤šä¸“å®¶å·¥å…·
- [ ] æ·»åŠ å·¥å…·æ‰§è¡Œç­–ç•¥é…ç½®
- [ ] å®ç°å·¥å…·ç»“æœç¼“å­˜
- [ ] æ”¯æŒæµå¼å¤„ç†
- [ ] æ·»åŠ æ€§èƒ½ç›‘æ§
- [ ] å®Œå–„æ–‡æ¡£å’Œæ•™ç¨‹





