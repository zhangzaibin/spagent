# é«˜çº§ä½¿ç”¨ç¤ºä¾‹

> **English Version**: [English Document](ADVANCED_EXAMPLES.md) | **ä¸­æ–‡ç‰ˆæœ¬**: å½“å‰æ–‡æ¡£

æœ¬æŒ‡å—æä¾›äº† SPAgent çš„é«˜çº§ä½¿ç”¨ç¤ºä¾‹å’Œç­–ç•¥ï¼ŒåŒ…æ‹¬ä¸“é—¨åŒ–ä»£ç†ã€å·¥å…·æ··åˆç­–ç•¥å’Œå¤æ‚å·¥ä½œæµã€‚

## ğŸ“‹ ç›®å½•

- [å‘½ä»¤è¡Œç¤ºä¾‹](#å‘½ä»¤è¡Œç¤ºä¾‹)
- [ä¸“é—¨åŒ–ä»£ç†ç¤ºä¾‹](#ä¸“é—¨åŒ–ä»£ç†ç¤ºä¾‹)
- [å·¥å…·æ··åˆç­–ç•¥](#å·¥å…·æ··åˆç­–ç•¥)
- [è§†é¢‘åˆ†ææµ‹è¯•](#è§†é¢‘åˆ†ææµ‹è¯•)
- [å¼ºåŒ–å­¦ä¹ è®­ç»ƒ](#å¼ºåŒ–å­¦ä¹ è®­ç»ƒ)

## å‘½ä»¤è¡Œç¤ºä¾‹

### åŸºæœ¬å‘½ä»¤è¡Œç”¨æ³•

```bash
# åœ¨æ•°æ®é›†ä¸Šè¿è¡Œè¯„ä¼°
python examples/evaluation/evaluate_img.py \
    --data_path dataset/your_data.jsonl \
    --model gpt-4o-mini \
    --max_samples 10 \
    --max_iterations 3

# æ— å·¥å…·è¯„ä¼°ï¼ˆåŸºçº¿ï¼‰
python examples/evaluation/evaluate_img_wotools.py \
    --data_path dataset/your_data.jsonl \
    --model gpt-4o-mini \
    --max_samples 10

# è¯„ä¼°æ—¶æ”¶é›†è®­ç»ƒæ•°æ®
python examples/evaluation/evaluate_img_with_data_collection.py \
    --data_path dataset/your_data.jsonl \
    --model gpt-4o-mini \
    --max_samples 10 \
    --enable_data_collection
```

## ä¸“é—¨åŒ–ä»£ç†ç¤ºä¾‹

é€šè¿‡é€‰æ‹©é€‚å½“çš„å·¥å…·ç»„åˆï¼Œåˆ›å»ºé’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„ä¸“é—¨åŒ–ä»£ç†ã€‚

### 1. æ·±åº¦åˆ†æä¸“é—¨åŒ–ä»£ç†

æ„å»ºä¸“æ³¨äºæ·±åº¦åˆ†æä»»åŠ¡çš„ä»£ç†ï¼š

```python
from spagent import SPAgent
from spagent.models import GPTModel
from spagent.tools import DepthEstimationTool, SegmentationTool

# ä¸“é—¨ç”¨äºæ·±åº¦åˆ†æçš„ä»£ç†
model = GPTModel(model_name="gpt-4o-mini")
depth_tools = [
    DepthEstimationTool(use_mock=True),
    SegmentationTool(use_mock=True)  # è¾…åŠ©åˆ†å‰²
]

depth_agent = SPAgent(model=model, tools=depth_tools)
result = depth_agent.solve_problem(
    "image.jpg", 
    "Analyze the depth distribution of the image: which objects are close to the camera and which are far?"
)
```

### 2. ç‰©ä½“æ£€æµ‹ä¸“é—¨åŒ–ä»£ç†

åˆ›å»ºé’ˆå¯¹ç‰©ä½“æ£€æµ‹ä»»åŠ¡ä¼˜åŒ–çš„ä»£ç†ï¼š

```python
from spagent import SPAgent
from spagent.models import GPTModel
from spagent.tools import ObjectDetectionTool, SupervisionTool, YOLOETool, SegmentationTool

# ä¸“é—¨ç”¨äºç‰©ä½“æ£€æµ‹çš„ä»£ç†
model = GPTModel(model_name="gpt-4o-mini")
detection_tools = [
    ObjectDetectionTool(use_mock=True),
    SupervisionTool(use_mock=True),
    YOLOETool(use_mock=True),
    SegmentationTool(use_mock=True)  # è¾…åŠ©åˆ†å‰²
]

detection_agent = SPAgent(model=model, tools=detection_tools)
result = detection_agent.solve_problem(
    "image.jpg", 
    "Detect and identify all objects in the image, including their positions and types"
)
```

### 3. è‡ªå®šä¹‰å·¥å…·ç»„åˆ

æ ¹æ®éœ€æ±‚æ¡ä»¶æ€§åœ°æ·»åŠ å·¥å…·ï¼ŒåŠ¨æ€æ„å»ºä»£ç†ï¼š

```python
from spagent import SPAgent
from spagent.models import GPTModel
from spagent.tools import DepthEstimationTool, ObjectDetectionTool, SegmentationTool

# åˆ›å»ºä¸€ä¸ªç©ºä»£ç†å¹¶é€æ­¥æ·»åŠ å·¥å…·
agent = SPAgent(model=GPTModel())

# æ ¹æ®éœ€è¦æ·»åŠ å·¥å…·
if need_depth:
    agent.add_tool(DepthEstimationTool(use_mock=True))

if need_detection:
    agent.add_tool(ObjectDetectionTool(use_mock=True))
    
if need_segmentation:
    agent.add_tool(SegmentationTool(use_mock=True))

# ä½¿ç”¨é…ç½®å¥½çš„ä»£ç†
result = agent.solve_problem("image.jpg", "Analyze the image using available tools")
```

## å·¥å…·æ··åˆç­–ç•¥

SPAgent æä¾›äº†å¼ºå¤§çš„ç­–ç•¥æ¥ç»„åˆå¤šä¸ªå·¥å…·ä»¥è§£å†³å¤æ‚çš„è§†è§‰ä»»åŠ¡ã€‚

### 1. å¹¶è¡Œå·¥å…·æ‰§è¡Œ

SPAgent è‡ªåŠ¨æ£€æµ‹å¯ä»¥å¹¶è¡Œæ‰§è¡Œçš„å·¥å…·ï¼Œæé«˜æ€§èƒ½ï¼š

```python
# è¿™ä¸ªé—®é¢˜å°†è§¦å‘å¤šä¸ªå·¥å…·å¹¶è¡Œæ‰§è¡Œ
result = agent.solve_problem(
    "image.jpg",
    "Perform depth estimation, object detection, and image segmentation simultaneously"  # å°†å¹¶è¡Œæ‰§è¡Œ 3 ä¸ªå·¥å…·
)
```

### 2. æ¡ä»¶å·¥å…·é€‰æ‹©

æ¨¡å‹ä¼šæ ¹æ®é—®é¢˜æè¿°è‡ªåŠ¨é€‰æ‹©æ‰€éœ€çš„å·¥å…·ï¼š

```python
# åªä¼šä½¿ç”¨ä¸æ·±åº¦ç›¸å…³çš„å·¥å…·
result1 = agent.solve_problem("image.jpg", "Analyze depth relationships")

# åªä¼šä½¿ç”¨ä¸æ£€æµ‹ç›¸å…³çš„å·¥å…·  
result2 = agent.solve_problem("image.jpg", "Detect vehicles and pedestrians")

# å°†ä½¿ç”¨å¤šä¸ªå·¥å…·
result3 = agent.solve_problem("image.jpg", "Comprehensively analyze the image")
```

### 3. å·¥å…·é“¾ç»„åˆ

åˆ›å»ºå·¥å…·æŒ‰é¡ºåºä½¿ç”¨çš„å¤æ‚å¤„ç†ç®¡é“ï¼š

```python
# å¤æ‚çš„å·¥å…·é“¾ï¼šæ£€æµ‹ â†’ åˆ†å‰² â†’ æ·±åº¦åˆ†æ
result = agent.solve_problem(
    "image.jpg",
    """
    First detect the main objects in the image,
    then perform precise segmentation on the detected objects,
    finally analyze the depth relationships of these objects
    """
)
```

## è§†é¢‘åˆ†ææµ‹è¯•

SPAgent æ”¯æŒé€šè¿‡æå–è§†é¢‘å¸§å¹¶ä½¿ç”¨ Pi3 ç­‰å·¥å…·è¿›è¡Œ 3D é‡å»ºæ¥åˆ†æè§†é¢‘ã€‚

### åŸºæœ¬è§†é¢‘å¸§åˆ†æ

```python
# test/test_pi3_llm.py - å®Œæ•´çš„è§†é¢‘åˆ†æç¤ºä¾‹
import cv2
from pathlib import Path
from spagent.core.spagent import SPAgent
from spagent.models import GPTModel
from spagent.tools import Pi3Tool

def extract_video_frames(video_path: str, num_frames: int = 10):
    """ä»è§†é¢‘ä¸­å‡åŒ€æå–å¸§"""
    cap = cv2.VideoCapture(video_path)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    frame_interval = total_frames / num_frames
    
    frame_paths = []
    temp_dir = Path("temp_frames")
    temp_dir.mkdir(exist_ok=True)
    
    for i in range(num_frames):
        frame_idx = int(i * frame_interval)
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()
        if ret:
            frame_path = temp_dir / f"frame_{i}.jpg"
            cv2.imwrite(str(frame_path), frame)
            frame_paths.append(str(frame_path))
    
    cap.release()
    return frame_paths

# é…ç½®æ¨¡å‹å’Œ Pi3 å·¥å…·
model = GPTModel(model_name="gpt-4o-mini", temperature=0.7)
tools = [Pi3Tool(use_mock=False, server_url="http://localhost:20030")]

agent = SPAgent(model=model, tools=tools, max_workers=4)

# ä»è§†é¢‘ä¸­æå–å¸§
video_path = "path/to/video.mp4"
frame_paths = extract_video_frames(video_path, num_frames=10)

# ä½¿ç”¨ Pi3 3D é‡å»ºåˆ†æè§†é¢‘å¸§
result = agent.solve_problem(
    frame_paths,
    "Based on these frames from a video, which direction did the object move?",
    video_path=video_path,  # ä¼ é€’è§†é¢‘è·¯å¾„ï¼ŒPi3 å¯ä»¥æå–æ›´å¤šå¸§
    pi3_num_frames=50  # Pi3 åˆ†æä½¿ç”¨çš„å¸§æ•°
)

print(f"ç­”æ¡ˆ: {result['answer']}")
print(f"ä½¿ç”¨çš„å·¥å…·: {result['used_tools']}")
```

## å¼ºåŒ–å­¦ä¹ è®­ç»ƒ

SPAgent æ”¯æŒä½¿ç”¨ [ms-swift](https://github.com/modelscope/ms-swift) è¿›è¡Œ GRPOï¼ˆGroup Relative Policy Optimizationï¼‰å¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚

### è®­ç»ƒè„šæœ¬æ¦‚è§ˆ

| è„šæœ¬ | æè¿° |
|------|------|
| `train/train_grpo.sh` | å¸¦å·¥å…·è°ƒç”¨çš„æ ‡å‡† GRPO è®­ç»ƒ |
| `train/train_grpo_all_angles.sh` | ä½¿ç”¨æ‰€æœ‰è§’åº¦ç»„åˆçš„ GRPO è®­ç»ƒ |
| `train/train_grpo_notool.sh` | ä¸ä½¿ç”¨å·¥å…·è°ƒç”¨çš„ GRPO è®­ç»ƒï¼ˆåŸºçº¿ï¼‰ |
| `train/merge_lora.sh` | å°† LoRA é€‚é…å™¨åˆå¹¶åˆ°åŸºç¡€æ¨¡å‹ |
| `train/compress_model.sh` | å‹ç¼©è®­ç»ƒåçš„æ¨¡å‹æ£€æŸ¥ç‚¹ |

### è¿è¡Œè®­ç»ƒ

```bash
# å¸¦å·¥å…·è°ƒç”¨çš„æ ‡å‡† GRPO è®­ç»ƒ
cd train
bash train_grpo.sh

# æ— å·¥å…·è®­ç»ƒï¼ˆç”¨äºåŸºçº¿å¯¹æ¯”ï¼‰
bash train_grpo_notool.sh

# ä½¿ç”¨æ‰€æœ‰è§’åº¦ç»„åˆè®­ç»ƒï¼ˆç”¨äº Pi3ï¼‰
bash train_grpo_all_angles.sh
```

### å…³é”®è®­ç»ƒé…ç½®

```bash
# GRPO è®­ç»ƒé…ç½®ç¤ºä¾‹
swift rlhf \
    --rlhf_type grpo \
    --model path/to/Qwen3-VL-4B-Instruct \
    --external_plugins plugin/plugin.py \
    --multi_turn_scheduler spagent_tool_call_scheduler \
    --max_turns 3 \                              # æœ€å¤§å·¥å…·è°ƒç”¨è½®æ•°
    --reward_funcs external_r1v_acc external_multiturn_format \
    --reward_weights 1.0 1.0 \
    --train_type full \
    --torch_dtype bfloat16 \
    --dataset path/to/training_data.jsonl \
    --max_completion_length 1024 \
    --learning_rate 1e-6 \
    --num_generations 8 \                        # æ¯ä¸ªæ ·æœ¬çš„ç”Ÿæˆæ•°é‡
    --temperature 0.6 \
    --deepspeed zero2 \
    --output_dir output/grpo_experiment
```

### è®­ç»ƒåæ“ä½œ

```bash
# å°† LoRA æƒé‡åˆå¹¶åˆ°åŸºç¡€æ¨¡å‹
swift export \
    --adapters output/grpo_xxx/checkpoint-xxx \
    --merge_lora true

# å‹ç¼©æ¨¡å‹æ£€æŸ¥ç‚¹ç”¨äºéƒ¨ç½²
bash train/compress_model.sh
```

### ç³»ç»Ÿæç¤ºè¯

ä¸åŒçš„è®­ç»ƒæ¨¡å¼ä½¿ç”¨ä½äº `train/system_prompt/` çš„ä¸åŒç³»ç»Ÿæç¤ºè¯ï¼š

- `system_prompt_grpo.txt` - å¸¦å·¥å…·è°ƒç”¨çš„æ ‡å‡†è®­ç»ƒ
- `system_prompt_grpo_all_angles.txt` - ä½¿ç”¨æ‰€æœ‰è§’åº¦ç»„åˆçš„è®­ç»ƒ
- `system_prompt_grpo_wotool.txt` - æ— å·¥å…·è®­ç»ƒ

## ç›¸å…³æ–‡æ¡£

- [å¿«é€Ÿå…¥é—¨æŒ‡å—](../../readme.md#-quick-start)
- [å·¥å…·å‚è€ƒ](../Tool/TOOL_USING.md)
- [è¯„ä¼°æŒ‡å—](../Evaluation/EVALUATION.md)

---

æ›´å¤šä¿¡æ¯æˆ–æ”¯æŒï¼Œè¯·å‚è€ƒä¸» [README](../../readme.md) æˆ–åœ¨ GitHub ä¸Šæäº¤é—®é¢˜ã€‚

