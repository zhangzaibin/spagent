# SPAgent æ•°æ®é‡‡é›†åŠŸèƒ½ - å®Œæ•´æŒ‡å—

## ğŸ“‹ ç›®å½•

1. [åŠŸèƒ½æ¦‚è¿°](#åŠŸèƒ½æ¦‚è¿°)
2. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
3. [å®Œæ•´å®ç°è¯´æ˜](#å®Œæ•´å®ç°è¯´æ˜)
4. [ä½¿ç”¨åœºæ™¯](#ä½¿ç”¨åœºæ™¯)
5. [æ–‡ä»¶ç»“æ„](#æ–‡ä»¶ç»“æ„)
6. [ç¤ºä¾‹ä»£ç ](#ç¤ºä¾‹ä»£ç )

---

## åŠŸèƒ½æ¦‚è¿°

SPAgent ç°å·²æ”¯æŒå®Œæ•´çš„è®­ç»ƒæ•°æ®é‡‡é›†åŠŸèƒ½ï¼Œç”¨äºæ”¶é›†å¤šæ¨¡æ€å¤§æ¨¡å‹è®­ç»ƒæ•°æ®ã€‚

### âœ¨ æ ¸å¿ƒç‰¹æ€§

- âœ… **è‡ªåŠ¨é‡‡é›†**ï¼šæ¯æ¬¡æ¨ç†è‡ªåŠ¨è®°å½•è¾“å…¥ï¼ˆå›¾ç‰‡+promptï¼‰å’Œè¾“å‡ºï¼ˆresponseï¼‰
- âœ… **å¤šè½®æ”¯æŒ**ï¼šæ¯è½®æ¨ç†ä½œä¸ºç‹¬ç«‹æ ·æœ¬ï¼Œå®Œæ•´è®°å½•æ¨ç†é“¾
- âœ… **æ™ºèƒ½è¿‡æ»¤**ï¼šåªä¿å­˜æˆåŠŸçš„ä¼šè¯ï¼ˆæœ‰å®Œæ•´ç­”æ¡ˆçš„æ ·æœ¬ï¼‰
- âœ… **ä¸Šä¸‹æ–‡å®Œæ•´**ï¼šä¿å­˜å·¥å…·è°ƒç”¨ã€ç»“æœã€é¢å¤–å›¾ç‰‡ç­‰æ‰€æœ‰ä¿¡æ¯
- âœ… **å¤šç§æ ¼å¼**ï¼šæ”¯æŒ JSONLã€JSONã€ShareGPT ç­‰è®­ç»ƒæ ¼å¼
- âœ… **ç»Ÿè®¡ç›‘æ§**ï¼šå®æ—¶ç»Ÿè®¡é‡‡é›†è¿›åº¦å’ŒæˆåŠŸç‡

### ğŸ¯ è®¾è®¡ç›®æ ‡

æ‚¨æå‡ºçš„éœ€æ±‚ï¼š
> "æ¯æ¬¡æ¨ç†éƒ½è¦å°†å…¶ä¿å­˜ä¸‹æ¥ï¼ŒåŒ…æ‹¬å›¾ç‰‡æ–‡æœ¬ç­‰æ‰€æœ‰ memory å’Œè¾“å‡ºçš„ languageã€‚åªè¦æˆåŠŸçš„æ ·æœ¬ã€‚å¤šè½®æ‰§è¡Œå®ŒæˆåŠŸäº†ï¼Œæ‰€æœ‰çš„æ•°æ®æ ·æœ¬å°±éƒ½æ˜¯æˆåŠŸçš„æ­£æ ·æœ¬ã€‚"

âœ… **å·²å®Œæ•´å®ç°**

---

## å¿«é€Ÿå¼€å§‹

### æ–¹å¼ä¸€ï¼šåŸºç¡€ä½¿ç”¨ï¼ˆ3 è¡Œä»£ç ï¼‰

```python
from spagent.core import SPAgent, Model, DataCollector

# 1. åˆ›å»º DataCollector
collector = DataCollector(
    output_dir="training_data",
    save_images=True,
    auto_save=True
)

# 2. ä¼ é€’ç»™ SPAgent
agent = SPAgent(
    model=Model("Qwen/Qwen2-VL-7B-Instruct", "/path/to/model"),
    tools=[],  # ä½ çš„å·¥å…·åˆ—è¡¨
    data_collector=collector
)

# 3. æ­£å¸¸ä½¿ç”¨ï¼ˆè‡ªåŠ¨é‡‡é›†æ•°æ®ï¼‰
result = agent.solve_problem(
    image_path="image.jpg",
    question="è¿™å¼ å›¾ç‰‡ä¸­æœ‰ä»€ä¹ˆï¼Ÿ",
    max_iterations=3
)

# æ•°æ®å·²è‡ªåŠ¨ä¿å­˜åˆ° training_data/
```

### æ–¹å¼äºŒï¼šé›†æˆåˆ°è¯„ä¼°è„šæœ¬

```bash
# è¿è¡Œè¯„ä¼°å¹¶åŒæ—¶é‡‡é›†è®­ç»ƒæ•°æ®
python examples/evaluation/evaluate_img_with_data_collection.py \
    --data_path dataset/data.jsonl \
    --max_samples 100 \
    --model gpt-4o \
    --enable_data_collection \
    --max_iterations 3
```

è¯¦è§ï¼š[examples/evaluation/HOW_TO_ADD_DATA_COLLECTION.md](examples/evaluation/HOW_TO_ADD_DATA_COLLECTION.md)

---

## å®Œæ•´å®ç°è¯´æ˜

### 1. æ ¸å¿ƒæ¨¡å—

#### `spagent/core/data_collector.py` (æ–°å¢)

å®ç°äº†ä¸‰ä¸ªæ ¸å¿ƒç±»ï¼š

1. **InferenceSample**ï¼šå•æ¬¡æ¨ç†æ ·æœ¬
   - è®°å½•å›¾ç‰‡ã€promptã€responseã€ä¸Šä¸‹æ–‡
   - æ¯è½®æ¨ç†ç”Ÿæˆä¸€ä¸ªæ ·æœ¬

2. **SessionData**ï¼šå®Œæ•´ä¼šè¯æ•°æ®
   - åŒ…å«å¤šä¸ª InferenceSample
   - è®°å½•ä¼šè¯çº§åˆ«çš„å…ƒæ•°æ®

3. **DataCollector**ï¼šæ•°æ®æ”¶é›†å™¨
   - ç®¡ç†ä¼šè¯å’Œæ ·æœ¬
   - å¯¼å‡ºå¤šç§æ ¼å¼
   - æä¾›ç»Ÿè®¡åŠŸèƒ½

#### `spagent/core/spagent.py` (å·²ä¿®æ”¹)

é›†æˆäº† DataCollectorï¼š
- åœ¨ `solve_problem` å¼€å§‹æ—¶å¯åŠ¨ä¼šè¯
- æ¯æ¬¡æ¨ç†åè®°å½•æ ·æœ¬
- ç»“æŸæ—¶åˆ¤å®šæˆåŠŸå¹¶ä¿å­˜

### 2. æ•°æ®é‡‡é›†æµç¨‹

```
ç”¨æˆ·è°ƒç”¨ solve_problem()
    â†“
DataCollector.start_session()  # å¼€å§‹ä¼šè¯
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å¤šè½®æ¨ç†å¾ªç¯                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ æ¨¡å‹æ¨ç†            â”‚    â”‚
â”‚  â”‚  â†“                  â”‚    â”‚
â”‚  â”‚ record_inference()  â”‚    â”‚  # è®°å½•æœ¬è½®æ ·æœ¬
â”‚  â”‚  â†“                  â”‚    â”‚
â”‚  â”‚ å·¥å…·è°ƒç”¨ï¼ˆå¯é€‰ï¼‰    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
æå–ç­”æ¡ˆï¼Œåˆ¤å®šæˆåŠŸ
    â†“
DataCollector.end_session()    # ç»“æŸä¼šè¯
    â†“
å¦‚æœæˆåŠŸï¼šä¿å­˜æ‰€æœ‰æ ·æœ¬
å¦‚æœå¤±è´¥ï¼šä¸¢å¼ƒæ‰€æœ‰æ ·æœ¬
```

### 3. æˆåŠŸåˆ¤å®šé€»è¾‘

```python
def _extract_answer(self, response: str) -> Optional[str]:
    """æå– <answer> æ ‡ç­¾ä¸­çš„å†…å®¹"""
    pattern = r'<answer>(.*?)</answer>'
    match = re.search(pattern, response, re.DOTALL)
    return match.group(1).strip() if match else None

# åœ¨ solve_problem ç»“å°¾
extracted_answer = self._extract_answer(final_response)
success = extracted_answer is not None  # æœ‰ answer æ ‡ç­¾å³æˆåŠŸ
```

**å…³é”®ç‚¹**ï¼š
- âœ… åªè¦æ¨¡å‹è¿”å› `<answer>` æ ‡ç­¾ï¼Œå°±è®¤ä¸ºæˆåŠŸ
- âœ… æ— è®ºé¢„æµ‹æ˜¯å¦æ­£ç¡®ï¼Œéƒ½ä¿å­˜ï¼ˆå¯ç”¨äºåˆ†æå’Œè´Ÿé‡‡æ ·ï¼‰
- âœ… æ•´ä¸ªä¼šè¯æˆåŠŸï¼Œæ‰€æœ‰è½®æ¬¡çš„æ ·æœ¬éƒ½ä¿å­˜

### 4. å¤šè½®æ¨ç†ç¤ºä¾‹

å‡è®¾ `max_iterations=3`ï¼Œå®é™…æ‰§è¡Œäº† 3 è½®æ¨ç†ï¼š

**ä¼šè¯æµç¨‹**ï¼š
```
Iteration 1: åˆå§‹æ¨ç†
  â†’ Sample 1: {images: [img1.jpg], prompt: "...", response: "..."}

Iteration 2: è°ƒç”¨å·¥å…·åç»§ç»­æ¨ç†
  â†’ Sample 2: {images: [img1.jpg, depth.jpg], prompt: "...", response: "..."}

Iteration 3: è¿›ä¸€æ­¥åˆ†æ
  â†’ Sample 3: {images: [img1.jpg, depth.jpg, pi3.png], prompt: "...", response: "..."}

Final Synthesis: ç»¼åˆæœ€ç»ˆç­”æ¡ˆ
  â†’ Sample 4: {images: [...], prompt: "...", response: "<answer>...</answer>"}
```

**ç»“æœ**ï¼š
- å¦‚æœ Final Synthesis åŒ…å« `<answer>` æ ‡ç­¾ â†’ **æˆåŠŸ**ï¼Œä¿å­˜æ‰€æœ‰ 4 ä¸ªæ ·æœ¬
- å¦‚æœæ²¡æœ‰ `<answer>` æ ‡ç­¾ â†’ **å¤±è´¥**ï¼Œä¸ä¿å­˜ä»»ä½•æ ·æœ¬

---

## ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1ï¼šæ‰¹é‡é‡‡é›†è®­ç»ƒæ•°æ®

```python
from spagent.core import SPAgent, Model, DataCollector

# åˆå§‹åŒ–
collector = DataCollector("training_data")
agent = SPAgent(model, tools, data_collector=collector)

# æ‰¹é‡å¤„ç†
test_cases = [
    {"image": "img1.jpg", "question": "é—®é¢˜1"},
    {"image": "img2.jpg", "question": "é—®é¢˜2"},
    # ... æ›´å¤šæ ·æœ¬
]

for case in test_cases:
    try:
        agent.solve_problem(
            case["image"],
            case["question"],
            max_iterations=3
        )
    except Exception as e:
        print(f"Error: {e}")

# å¯¼å‡ºæ•°æ®
collector.export_for_training("train.jsonl", format="jsonl")
collector.save_statistics()

stats = collector.get_statistics()
print(f"æˆåŠŸç‡: {stats['success_rate']:.1%}")
print(f"æ€»æ ·æœ¬: {stats['total_samples']}")
```

### åœºæ™¯ 2ï¼šè¯„ä¼°æ—¶åŒæ—¶é‡‡é›†

```bash
# åœ¨è¯„ä¼°çš„åŒæ—¶é‡‡é›†è®­ç»ƒæ•°æ®
python examples/evaluation/evaluate_img_with_data_collection.py \
    --data_path dataset/cvbench_data.jsonl \
    --max_samples 1000 \
    --model gpt-4o \
    --enable_data_collection \
    --max_iterations 3
```

è¾“å‡ºï¼š
- è¯„ä¼°ç»“æœï¼š`spagent_evaluation_results_*.json`
- è®­ç»ƒæ•°æ®ï¼š`training_data/depth_detection_segmentation_*/`

### åœºæ™¯ 3ï¼šæ‰‹åŠ¨æ§åˆ¶é‡‡é›†

```python
# é«˜çº§ï¼šå®Œå…¨æ‰‹åŠ¨æ§åˆ¶
collector = DataCollector("training_data", auto_save=False)

session_id = collector.start_session(question, images)

# è‡ªå®šä¹‰æ¨ç†æµç¨‹
for iteration in range(3):
    response = custom_inference(...)
    
    collector.record_inference(
        iteration=iteration,
        images=current_images,
        prompt=prompt,
        response=response,
        context=custom_context
    )

# è‡ªå®šä¹‰æˆåŠŸåˆ¤å®š
if custom_success_criteria(response):
    collector.end_session(success=True, final_answer=response)
else:
    collector.end_session(success=False, error_message="æœªè¾¾æ ‡")
```

---

## æ–‡ä»¶ç»“æ„

### æ–°å¢æ–‡ä»¶

```
spagent/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ data_collector.py          # æ•°æ®é‡‡é›†æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ spagent.py                 # å·²ä¿®æ”¹ï¼šé›†æˆ DataCollector
â”‚   â””â”€â”€ __init__.py                # å·²ä¿®æ”¹ï¼šå¯¼å‡º DataCollector
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ data_collection_example.py              # è¯¦ç»†ç¤ºä¾‹
â”‚   â”œâ”€â”€ quick_start_data_collection.py          # å¿«é€Ÿå¼€å§‹ç¤ºä¾‹
â”‚   â””â”€â”€ evaluation/
â”‚       â”œâ”€â”€ evaluate_img_with_data_collection.py  # é›†æˆç‰ˆè¯„ä¼°è„šæœ¬
â”‚       â””â”€â”€ HOW_TO_ADD_DATA_COLLECTION.md         # é›†æˆæŒ‡å—
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ DATA_COLLECTION.md                      # ç”¨æˆ·ä½¿ç”¨æ–‡æ¡£
    â””â”€â”€ DATA_COLLECTION_IMPLEMENTATION.md       # å®ç°ç»†èŠ‚æ–‡æ¡£
```

### ç”Ÿæˆçš„æ•°æ®ç»“æ„

```
training_data/
â”œâ”€â”€ sessions/                    # æ‰€æœ‰ä¼šè¯
â”‚   â”œâ”€â”€ session_20250124_143022_abc123/
â”‚   â”‚   â”œâ”€â”€ session_metadata.json   # ä¼šè¯å®Œæ•´ä¿¡æ¯
â”‚   â”‚   â”œâ”€â”€ samples/                # å„ä¸ªæ¨ç†æ ·æœ¬
â”‚   â”‚   â”‚   â”œâ”€â”€ sample_1.json       # ç¬¬1è½®æ¨ç†
â”‚   â”‚   â”‚   â”œâ”€â”€ sample_2.json       # ç¬¬2è½®æ¨ç†
â”‚   â”‚   â”‚   â””â”€â”€ sample_3.json       # ç¬¬3è½®æ¨ç†
â”‚   â”‚   â””â”€â”€ images/                 # æ‰€æœ‰ç›¸å…³å›¾ç‰‡
â”‚   â”‚       â”œâ”€â”€ original.jpg
â”‚   â”‚       â”œâ”€â”€ depth_result.jpg
â”‚   â”‚       â””â”€â”€ pi3_result.png
â”‚   â””â”€â”€ session_20250124_143145_def456/
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ statistics.json              # é‡‡é›†ç»Ÿè®¡ä¿¡æ¯
â”œâ”€â”€ train.jsonl                  # JSONL æ ¼å¼è®­ç»ƒæ•°æ®
â””â”€â”€ train_sharegpt.json          # ShareGPT æ ¼å¼è®­ç»ƒæ•°æ®
```

---

## ç¤ºä¾‹ä»£ç 

### ç¤ºä¾‹ 1ï¼šå®Œæ•´çš„é‡‡é›†æµç¨‹

```python
from spagent.core import SPAgent, Model, DataCollector
from spagent.tools import DepthEstimationTool, Pi3Tool

# 1. åˆ›å»º DataCollector
collector = DataCollector(
    output_dir="my_training_data",
    save_images=True,
    auto_save=True
)

# 2. åˆ›å»º SPAgent
model = Model("Qwen/Qwen2-VL-7B-Instruct", "/path/to/model")
tools = [
    DepthEstimationTool(server_url="http://localhost:20019"),
    Pi3Tool(server_url="http://localhost:20030")
]

agent = SPAgent(
    model=model,
    tools=tools,
    data_collector=collector
)

# 3. è¿è¡Œæ¨ç†ï¼ˆè‡ªåŠ¨é‡‡é›†ï¼‰
result = agent.solve_problem(
    image_path="test_image.jpg",
    question="è¿™ä¸ªåœºæ™¯ä¸­æœ‰å¤šå°‘ä¸ªç‰©ä½“ï¼Ÿä»ä¸åŒè§’åº¦çœ‹æ˜¯å¦æœ‰é®æŒ¡ï¼Ÿ",
    max_iterations=3
)

print(f"ç­”æ¡ˆ: {result['answer']}")
print(f"ä½¿ç”¨çš„å·¥å…·: {result['used_tools']}")
print(f"è¿­ä»£æ¬¡æ•°: {result['iterations']}")

# 4. æŸ¥çœ‹ç»Ÿè®¡
stats = collector.get_statistics()
print(f"\né‡‡é›†ç»Ÿè®¡:")
print(f"  æ€»ä¼šè¯æ•°: {stats['total_sessions']}")
print(f"  æˆåŠŸä¼šè¯: {stats['successful_sessions']}")
print(f"  æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
print(f"  æˆåŠŸç‡: {stats['success_rate']:.1%}")

# 5. å¯¼å‡ºè®­ç»ƒæ•°æ®
collector.export_for_training("my_training_data/train.jsonl", format="jsonl")
collector.export_for_training("my_training_data/train_sharegpt.json", format="sharegpt")
collector.save_statistics()

print(f"\nâœ… è®­ç»ƒæ•°æ®å·²ä¿å­˜åˆ°: my_training_data/")
```

### ç¤ºä¾‹ 2ï¼šæŸ¥çœ‹é‡‡é›†çš„æ•°æ®

```python
import json
from pathlib import Path

# è¯»å–ä¼šè¯æ•°æ®
session_dir = Path("training_data/sessions/session_xxx")
with open(session_dir / "session_metadata.json") as f:
    session = json.load(f)

print(f"é—®é¢˜: {session['question']}")
print(f"æˆåŠŸ: {session['success']}")
print(f"æœ€ç»ˆç­”æ¡ˆ: {session['final_answer']}")
print(f"æ¨ç†è½®æ•°: {session['num_iterations']}")

# æŸ¥çœ‹å„ä¸ªæ ·æœ¬
for i, sample in enumerate(session['samples'], 1):
    print(f"\n=== æ ·æœ¬ {i} ===")
    print(f"è¿­ä»£: {sample['iteration']}")
    print(f"å›¾ç‰‡æ•°: {len(sample['images'])}")
    print(f"Prompt (å‰100å­—): {sample['prompt'][:100]}...")
    print(f"Response (å‰100å­—): {sample['response'][:100]}...")
```

### ç¤ºä¾‹ 3ï¼šåˆ†æé‡‡é›†æ•°æ®

```python
import json
from pathlib import Path
from collections import Counter

def analyze_training_data(data_dir):
    """åˆ†æé‡‡é›†çš„è®­ç»ƒæ•°æ®"""
    sessions_dir = Path(data_dir) / "sessions"
    
    stats = {
        "total_sessions": 0,
        "successful_sessions": 0,
        "total_samples": 0,
        "iteration_distribution": Counter(),
        "tool_usage": Counter()
    }
    
    for session_dir in sessions_dir.iterdir():
        if not session_dir.is_dir():
            continue
        
        with open(session_dir / "session_metadata.json") as f:
            session = json.load(f)
        
        stats["total_sessions"] += 1
        
        if session["success"]:
            stats["successful_sessions"] += 1
            stats["total_samples"] += len(session["samples"])
            stats["iteration_distribution"][session["num_iterations"]] += 1
            
            # ç»Ÿè®¡å·¥å…·ä½¿ç”¨
            for tool in session["metadata"].get("used_tools", []):
                stats["tool_usage"][tool] += 1
    
    # æ‰“å°æŠ¥å‘Š
    print("=" * 60)
    print("è®­ç»ƒæ•°æ®åˆ†ææŠ¥å‘Š")
    print("=" * 60)
    print(f"æ€»ä¼šè¯æ•°: {stats['total_sessions']}")
    print(f"æˆåŠŸä¼šè¯: {stats['successful_sessions']}")
    print(f"æ€»æ ·æœ¬æ•°: {stats['total_samples']}")
    print(f"æˆåŠŸç‡: {stats['successful_sessions']/stats['total_sessions']:.1%}")
    
    print(f"\nè¿­ä»£æ¬¡æ•°åˆ†å¸ƒ:")
    for num_iters, count in sorted(stats['iteration_distribution'].items()):
        print(f"  {num_iters} è½®: {count} ä¸ªä¼šè¯")
    
    print(f"\nå·¥å…·ä½¿ç”¨ç»Ÿè®¡:")
    for tool, count in stats['tool_usage'].most_common():
        print(f"  {tool}: {count} æ¬¡")
    
    return stats

# ä½¿ç”¨
analyze_training_data("training_data")
```

---

## å¯¼å‡ºæ ¼å¼è¯´æ˜

### 1. JSONL æ ¼å¼

æ¯è¡Œä¸€ä¸ªæ ·æœ¬ï¼Œä¾¿äºæµå¼åŠ è½½ï¼š

```jsonl
{"sample_id": "session_xxx_iter_1", "iteration": 1, "images": ["img.jpg"], "prompt": "...", "response": "..."}
{"sample_id": "session_xxx_iter_2", "iteration": 2, "images": ["img.jpg", "depth.jpg"], "prompt": "...", "response": "..."}
```

### 2. ShareGPT æ ¼å¼

é€‚ç”¨äºå¤šæ¨¡æ€å¯¹è¯æ¨¡å‹è®­ç»ƒï¼š

```json
[
  {
    "id": "session_xxx_iter_1",
    "images": ["img1.jpg", "img2.jpg"],
    "conversations": [
      {"from": "human", "value": "é—®é¢˜æ–‡æœ¬..."},
      {"from": "gpt", "value": "å›å¤æ–‡æœ¬..."}
    ]
  }
]
```

### 3. JSON æ ¼å¼

æ‰€æœ‰æ ·æœ¬åœ¨ä¸€ä¸ªæ•°ç»„ä¸­ï¼š

```json
[
  {
    "sample_id": "...",
    "iteration": 1,
    "images": [...],
    "prompt": "...",
    "response": "..."
  }
]
```

---

## æœ€ä½³å®è·µ

### âœ… æ¨èåšæ³•

1. **å°è§„æ¨¡æµ‹è¯•**ï¼šå…ˆç”¨ 10-20 ä¸ªæ ·æœ¬æµ‹è¯•æ•°æ®é‡‡é›†æ˜¯å¦æ­£å¸¸
2. **å®šæœŸå¤‡ä»½**ï¼šå¤§è§„æ¨¡é‡‡é›†æ—¶å®šæœŸå¤‡ä»½ `training_data/` ç›®å½•
3. **ç›‘æ§ç£ç›˜ç©ºé—´**ï¼šå¯ç”¨ `save_images=True` ä¼šå ç”¨è¾ƒå¤šç©ºé—´
4. **ä¿ç•™æ‰€æœ‰æ ·æœ¬**ï¼šåŒ…æ‹¬é”™è¯¯çš„æ ·æœ¬ï¼Œç”¨äºåˆ†æå’Œæ”¹è¿›
5. **ç‰ˆæœ¬ç®¡ç†**ï¼šä¸ºä¸åŒæ‰¹æ¬¡çš„æ•°æ®ä½¿ç”¨ä¸åŒçš„è¾“å‡ºç›®å½•

### âš ï¸ æ³¨æ„äº‹é¡¹

1. **å¹¶å‘é™åˆ¶**ï¼šå¤šè¿›ç¨‹é‡‡é›†æ—¶æ¯ä¸ªè¿›ç¨‹ä½¿ç”¨ç‹¬ç«‹çš„ `output_dir`
2. **å¼‚å¸¸å¤„ç†**ï¼šå³ä½¿é‡‡é›†å¤±è´¥ï¼Œè¯„ä¼°ä»ä¼šç»§ç»­
3. **æ•°æ®æ¸…ç†**ï¼šå®šæœŸæ¸…ç†ä¸éœ€è¦çš„æ—§æ•°æ®
4. **è·¯å¾„é—®é¢˜**ï¼šå»ºè®®ä½¿ç”¨ç»å¯¹è·¯å¾„æˆ– `save_images=True`

---

## æŠ€æœ¯æ”¯æŒ

- è¯¦ç»†æ–‡æ¡£ï¼š`docs/DATA_COLLECTION.md`
- å®ç°è¯´æ˜ï¼š`docs/DATA_COLLECTION_IMPLEMENTATION.md`
- ç¤ºä¾‹ä»£ç ï¼š`examples/data_collection_example.py`
- é›†æˆæŒ‡å—ï¼š`examples/evaluation/HOW_TO_ADD_DATA_COLLECTION.md`

---

## æ€»ç»“

âœ… **å®Œæ•´å®ç°äº†æ‚¨çš„éœ€æ±‚**ï¼š
- æ¯æ¬¡æ¨ç†éƒ½è®°å½•ï¼ˆå›¾ç‰‡+æ–‡æœ¬+è¾“å‡ºï¼‰
- åªä¿å­˜æˆåŠŸçš„æ ·æœ¬
- å¤šè½®æ‰§è¡ŒæˆåŠŸåï¼Œæ‰€æœ‰æ ·æœ¬éƒ½ä¿å­˜ä¸ºæ­£æ ·æœ¬
- åŒ…å«å®Œæ•´çš„ memory å’Œ context ä¿¡æ¯

ğŸ¯ **ä½¿ç”¨ç®€å•**ï¼š
- åªéœ€ 3 è¡Œä»£ç å³å¯å¯ç”¨
- è‡ªåŠ¨é‡‡é›†ï¼Œæ— éœ€æ‰‹åŠ¨å¹²é¢„
- æ”¯æŒæ‰¹é‡è¯„ä¼°æ—¶åŒæ—¶é‡‡é›†

ğŸ“¦ **åŠŸèƒ½å®Œå–„**ï¼š
- å¤šç§å¯¼å‡ºæ ¼å¼
- ç»Ÿè®¡å’Œç›‘æ§
- çµæ´»çš„æˆåŠŸåˆ¤å®š
- å®Œæ•´çš„æ–‡æ¡£å’Œç¤ºä¾‹

ç°åœ¨æ‚¨å¯ä»¥å¼€å§‹ä½¿ç”¨ SPAgent é‡‡é›†é«˜è´¨é‡çš„å¤šæ¨¡æ€è®­ç»ƒæ•°æ®äº†ï¼


