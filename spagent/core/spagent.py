"""
SPAgent - Spatial Intelligence Agent

This module contains the main SPAgent class that orchestrates problem solving
using external expert tools and VLLM models.
"""

import json
import re
import logging
import asyncio
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, Any, List, Optional, Union
from pathlib import Path

from .tool import Tool, ToolRegistry
from .model import Model
from .prompts import create_system_prompt, create_follow_up_prompt, create_user_prompt, create_fallback_prompt

logger = logging.getLogger(__name__)


class SPAgent:
    """
    Spatial Intelligence Agent
    
    An agent that can solve spatial intelligence problems by combining
    VLLM models with external expert tools.
    """
    
    def __init__(
        self, 
        model: Model,
        tools: Optional[List[Tool]] = None,
        max_workers: int = 4
    ):
        """
        Initialize SPAgent
        
        Args:
            model: VLLM model wrapper to use
            tools: List of external expert tools (optional)
            max_workers: Maximum number of parallel tool executions
        """
        self.model = model
        self.tool_registry = ToolRegistry()
        self.max_workers = max_workers
        
        # Register provided tools
        if tools:
            for tool in tools:
                self.add_tool(tool)
        
        logger.info(f"Initialized SPAgent with model: {model.model_name}")
    
    def add_tool(self, tool: Tool):
        """
        Add a tool to the agent
        
        Args:
            tool: Tool instance to add
        """
        self.tool_registry.register(tool)
    
    def remove_tool(self, tool_name: str):
        """
        Remove a tool from the agent
        
        Args:
            tool_name: Name of tool to remove
        """
        self.tool_registry.unregister(tool_name)
    
    def list_tools(self) -> List[str]:
        """
        Get list of available tool names
        
        Returns:
            List of tool names
        """
        return self.tool_registry.list_tools()
    
    def set_model(self, model: Model):
        """
        Set the VLLM model
        
        Args:
            model: Model instance to use
        """
        self.model = model
        logger.info(f"Updated model to: {model.model_name}")
    
    def solve_problem(
        self, 
        image_path: Union[str, List[str]], 
        question: str,
        **model_kwargs
    ) -> Dict[str, Any]:
        """
        Solve a spatial intelligence problem
        
        Args:
            image_path: Path to image or list of image paths
            question: User's question about the image(s)
            **model_kwargs: Additional arguments for model inference
            
        Returns:
            Dictionary containing:
            - answer: Final answer text
            - initial_response: Model's initial response
            - tool_calls: List of tool calls made
            - tool_results: Results from tool execution
            - used_tools: List of tools that were used
            - additional_images: List of additional images generated by tools
        """
        logger.info(f"Starting problem solving for question: {question}")
        
        # Validate inputs
        if isinstance(image_path, str):
            image_paths = [image_path]
        else:
            image_paths = image_path
        
        for path in image_paths:
            if not Path(path).exists():
                raise FileNotFoundError(f"Image not found: {path}")
        
        # Create system prompt with available tools
        tool_schemas = self.tool_registry.get_function_schemas()
        system_prompt = create_system_prompt(tool_schemas)
        user_prompt = create_user_prompt(question, image_paths)
        
        # Step 1: Get initial model response
        logger.info("Getting initial model response...")
        if len(image_paths) == 1:
            initial_response = self.model.single_image_inference(
                image_paths[0], 
                system_prompt + "\n\n" + user_prompt,
                **model_kwargs
            )
        else:
            initial_response = self.model.multiple_images_inference(
                image_paths,
                system_prompt + "\n\n" + user_prompt,
                **model_kwargs
            )
        
        logger.info(f"Initial response: {initial_response}")
        
        # Step 2: Parse tool calls from response
        tool_calls = self._parse_tool_calls(initial_response)
        
        if not tool_calls:
            logger.info("No tool calls found, returning initial response")
            return {
                "answer": initial_response,
                "initial_response": initial_response,
                "tool_calls": [],
                "tool_results": {},
                "used_tools": [],
                "additional_images": [],
                "prompts": {
                    "system_prompt": system_prompt,
                    "user_prompt": user_prompt,
                    "follow_up_prompt": None
                }
            }
        
        # Step 3: Execute tools
        logger.info(f"Executing {len(tool_calls)} tool calls...")
        tool_results = self._execute_tools(tool_calls)
        
        # Step 4: Collect successful tool results and additional images
        successful_tools = []
        additional_images = []
        
        for tool_name, result in tool_results.items():
            if result.get('success'):
                successful_tools.append(tool_name)
                # Collect additional images from tool results (filter out None values)
                if 'output_path' in result and result['output_path'] is not None:
                    if Path(result['output_path']).exists():
                        additional_images.append(result['output_path'])
                if 'vis_path' in result and result['vis_path'] is not None:
                    if Path(result['vis_path']).exists():
                        additional_images.append(result['vis_path'])
        
        # Step 5: Generate final response with tool results
        if successful_tools:
            logger.info(f"Generating final response with results from {len(successful_tools)} tools...")
            follow_up_prompt = create_follow_up_prompt(
                question, 
                initial_response, 
                tool_results,
                image_paths,
                additional_images
            )
            
            # Include additional images in final inference if available (filter out None and invalid paths)
            # And ensure the order matches the original image_paths order
            valid_additional_images = self._sort_additional_images_by_input_order(image_paths, additional_images)
            all_images = image_paths + valid_additional_images
            
            if len(all_images) == 1:
                final_response = self.model.single_image_inference(
                    all_images[0],
                    follow_up_prompt,
                    **model_kwargs
                )
            else:
                final_response = self.model.multiple_images_inference(
                    all_images,
                    follow_up_prompt,
                    **model_kwargs
                )
        else:
            logger.warning("No tools executed successfully, generating fallback response")
            # Check if initial_response contains <answer> tags
            if self._has_answer_tags(initial_response):
                final_response = initial_response
            else:
                # Generate a proper response with <answer> tags when tools fail
                fallback_prompt = create_fallback_prompt(question, initial_response)
                if len(image_paths) == 1:
                    final_response = self.model.single_image_inference(
                        image_paths[0],
                        fallback_prompt,
                        **model_kwargs
                    )
                else:
                    final_response = self.model.multiple_images_inference(
                        image_paths,
                        fallback_prompt,
                        **model_kwargs
                    )
        
        return {
            "answer": final_response,
            "initial_response": initial_response,
            "tool_calls": tool_calls,
            "tool_results": tool_results,
            "used_tools": successful_tools,
            "additional_images": additional_images,
            "prompts": {
                "system_prompt": system_prompt,
                "user_prompt": user_prompt,
                "follow_up_prompt": follow_up_prompt if successful_tools else None
            }
        }
    
    def _parse_tool_calls(self, response: str) -> List[Dict[str, Any]]:
        """
        Parse tool calls from model response
        
        Args:
            response: Model response text
            
        Returns:
            List of tool call dictionaries
        """
        tool_calls = []
        
        # Find all tool_call blocks
        pattern = r'<tool_call>\s*({.*?})\s*</tool_call>'
        matches = re.findall(pattern, response, re.DOTALL)
        
        for match in matches:
            try:
                tool_call = json.loads(match)
                if 'name' in tool_call and 'arguments' in tool_call:
                    tool_calls.append(tool_call)
                else:
                    logger.warning(f"Invalid tool call format: {match}")
            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse tool call JSON: {match}, error: {e}")
        
        return tool_calls
    
    def _execute_tools(self, tool_calls: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Execute tool calls in parallel when possible
        
        Args:
            tool_calls: List of tool call dictionaries
            
        Returns:
            Dictionary of tool_name -> result
        """
        tool_results = {}
        
        # Group tool calls by tool name to handle multiple calls to same tool
        tool_groups = {}
        for i, call in enumerate(tool_calls):
            tool_name = call['name']
            if tool_name not in tool_groups:
                tool_groups[tool_name] = []
            tool_groups[tool_name].append((i, call))
        
        # Execute tools in parallel, but Pi3Tool sequentially to avoid server issues
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_tool = {}
            
            # Handle Pi3Tool calls sequentially first
            pi3_calls = []
            other_calls = {}
            
            for tool_name, calls in tool_groups.items():
                if tool_name == 'pi3_tool':
                    pi3_calls.extend(calls)
                else:
                    other_calls[tool_name] = calls
            
            # Execute Pi3Tool calls sequentially
            if pi3_calls:
                logger.info(f"Executing {len(pi3_calls)} Pi3Tool calls sequentially...")
                pi3_tool = self.tool_registry.get('pi3_tool')
                if pi3_tool:
                    for call_idx, call in pi3_calls:
                        result = self._safe_tool_call(pi3_tool, call['arguments'])
                        result_key = 'pi3_tool' if len(pi3_calls) == 1 else f"pi3_tool_{call_idx}"
                        tool_results[result_key] = result
                        # Add small delay between Pi3Tool calls
                        import time
                        time.sleep(1)
                else:
                    logger.error("Pi3Tool not found")
                    for call_idx, call in pi3_calls:
                        result_key = 'pi3_tool' if len(pi3_calls) == 1 else f"pi3_tool_{call_idx}"
                        tool_results[result_key] = {
                            "success": False,
                            "error": "Pi3Tool not found"
                        }
            
            # Execute other tools in parallel as before
            for tool_name, calls in other_calls.items():
                tool = self.tool_registry.get(tool_name)
                if tool is None:
                    logger.error(f"Tool not found: {tool_name}")
                    for _, call in calls:
                        tool_results[f"{tool_name}_{_}"] = {
                            "success": False,
                            "error": f"Tool not found: {tool_name}"
                        }
                    continue
                
                # Submit tool execution for each call
                for call_idx, call in calls:
                    future = executor.submit(self._safe_tool_call, tool, call['arguments'])
                    future_to_tool[future] = (tool_name, call_idx)
            
            # Collect results from parallel execution
            for future in as_completed(future_to_tool):
                tool_name, call_idx = future_to_tool[future]
                try:
                    result = future.result()
                    # Use unique key for multiple calls to same tool
                    result_key = tool_name if len([t for t in other_calls.get(tool_name, [])]) == 1 else f"{tool_name}_{call_idx}"
                    tool_results[result_key] = result
                except Exception as e:
                    logger.error(f"Tool execution failed for {tool_name}: {e}")
                    result_key = tool_name if len([t for t in other_calls.get(tool_name, [])]) == 1 else f"{tool_name}_{call_idx}"
                    tool_results[result_key] = {
                        "success": False,
                        "error": str(e)
                    }
        
        return tool_results
    
    def _safe_tool_call(self, tool: Tool, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """
        Safely execute a tool call with error handling
        
        Args:
            tool: Tool instance
            arguments: Tool arguments
            
        Returns:
            Tool execution result
        """
        try:
            logger.info(f"Executing tool: {tool.name} with args: {arguments}")
            result = tool.call(**arguments)
            logger.info(f"Tool {tool.name} completed successfully")
            return result
        except Exception as e:
            logger.error(f"Tool {tool.name} execution failed: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _sort_additional_images_by_input_order(self, image_paths: List[str], additional_images: List[str]) -> List[str]:
        """
        Sort additional images to match the order of input image_paths
        
        Args:
            image_paths: Original input image paths in order
            additional_images: Generated additional images (may be in different order)
            
        Returns:
            List of valid additional images sorted by input order
        """
        # Filter out None and invalid paths first
        valid_additional_images = [img for img in additional_images if img is not None and Path(img).exists()]
        
        if not valid_additional_images:
            return []
        
        # Create a sorted list of additional images based on input order
        sorted_additional_images = []
        
        for input_path in image_paths:
            input_stem = Path(input_path).stem
            
            # Find all additional images that correspond to this input image
            matching_images = []
            
            for additional_img in valid_additional_images:
                if additional_img in sorted_additional_images:
                    continue  # Already matched
                
                additional_stem = Path(additional_img).stem
                
                # Check if this additional image corresponds to the current input image
                if self._is_image_match(input_stem, additional_stem):
                    matching_images.append(additional_img)
            
            # Add matching images in a consistent order (by filename)
            matching_images.sort()
            sorted_additional_images.extend(matching_images)
        
        # Add any remaining unmatched additional images at the end
        for additional_img in valid_additional_images:
            if additional_img not in sorted_additional_images:
                sorted_additional_images.append(additional_img)
        
        logger.info(f"Sorted additional images: {[Path(img).name for img in sorted_additional_images]}")
        return sorted_additional_images
    
    def _is_image_match(self, input_stem: str, additional_stem: str) -> bool:
        """
        Check if an additional image corresponds to an input image
        
        Args:
            input_stem: Stem of input image filename
            additional_stem: Stem of additional image filename
            
        Returns:
            True if they match, False otherwise
        """
        # Since the suffix of saved images is always the same as the original image name,
        # we check if the additional image name ends with the input image name
        # This handles any prefix automatically without needing to maintain a list
        return additional_stem.endswith(input_stem)
    
    def _has_answer_tags(self, response: str) -> bool:
        """
        Check if response contains <answer> tags
        
        Args:
            response: Response text to check
            
        Returns:
            True if response contains <answer> tags, False otherwise
        """
        return '<answer>' in response and '</answer>' in response