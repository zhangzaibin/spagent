"""
SPAgent - Spatial Intelligence Agent

This module contains the main SPAgent class that orchestrates problem solving
using external expert tools and VLLM models.
"""

import json
import re
import logging
import asyncio
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, Any, List, Optional, Union
from pathlib import Path

from .tool import Tool, ToolRegistry
from .model import Model
from .prompts import create_system_prompt, create_follow_up_prompt, create_user_prompt, create_fallback_prompt

logger = logging.getLogger(__name__)


class SPAgent:
    """
    Spatial Intelligence Agent
    
    An agent that can solve spatial intelligence problems by combining
    VLLM models with external expert tools.
    """
    
    def __init__(
        self, 
        model: Model,
        tools: Optional[List[Tool]] = None,
        max_workers: int = 4
    ):
        """
        Initialize SPAgent
        
        Args:
            model: VLLM model wrapper to use
            tools: List of external expert tools (optional)
            max_workers: Maximum number of parallel tool executions
        """
        self.model = model
        self.tool_registry = ToolRegistry()
        self.max_workers = max_workers
        
        # Register provided tools
        if tools:
            for tool in tools:
                self.add_tool(tool)
        
        logger.info(f"Initialized SPAgent with model: {model.model_name}")
    
    def add_tool(self, tool: Tool):
        """
        Add a tool to the agent
        
        Args:
            tool: Tool instance to add
        """
        self.tool_registry.register(tool)
    
    def remove_tool(self, tool_name: str):
        """
        Remove a tool from the agent
        
        Args:
            tool_name: Name of tool to remove
        """
        self.tool_registry.unregister(tool_name)
    
    def list_tools(self) -> List[str]:
        """
        Get list of available tool names
        
        Returns:
            List of tool names
        """
        return self.tool_registry.list_tools()
    
    def set_model(self, model: Model):
        """
        Set the VLLM model
        
        Args:
            model: Model instance to use
        """
        self.model = model
        logger.info(f"Updated model to: {model.model_name}")
    
    def solve_problem(
        self, 
        image_path: Union[str, List[str]], 
        question: str,
        max_iterations: int = 3,
        video_path: Optional[str] = None,
        pi3_target_fps: float = 1.0,
        **model_kwargs
    ) -> Dict[str, Any]:
        """
        Solve a spatial intelligence problem
        
        Args:
            image_path: Path to image or list of image paths
            question: User's question about the image(s)
            max_iterations: Maximum number of tool-call iterations (default: 1)
            video_path: Optional path to original video (for pi3 tool re-sampling)
            pi3_target_fps: Target FPS for pi3 tool frame extraction (default 1.0)
            **model_kwargs: Additional arguments for model inference
            
        Returns:
            Dictionary containing:
            - answer: Final answer text
            - initial_response: Model's initial response
            - tool_calls: List of tool calls made
            - tool_results: Results from tool execution
            - used_tools: List of tools that were used
            - additional_images: List of additional images generated by tools
            - iterations: Number of iterations performed
        """
        logger.info(f"Starting problem solving for question: {question} (max_iterations={max_iterations})")
        
        # Validate inputs
        if isinstance(image_path, str):
            image_paths = [image_path]
        else:
            image_paths = image_path
        
        for path in image_paths:
            if not Path(path).exists():
                raise FileNotFoundError(f"Image not found: {path}")
        
        # Create system prompt with available tools
        tool_schemas = self.tool_registry.get_function_schemas()
        system_prompt = create_system_prompt(tool_schemas)
        # system_prompt += '\nThis time, you need to call the function anyway in <tool_call></tool_call> format.' # Debug Only!
        user_prompt = create_user_prompt(question, image_paths)
        
        # Initialize tracking variables for multi-step workflow
        all_tool_calls = []
        all_tool_results = {}
        all_additional_images = []
        all_successful_tools = []
        current_images = image_paths
        initial_response = None
        last_response = None
        iteration = 0
        
        # Multi-step workflow loop
        while iteration < max_iterations:
            iteration += 1
            logger.info(f"=== Iteration {iteration}/{max_iterations} ===")
            
            # Step 1: Get model response
            if iteration == 1:
                # First iteration: use initial prompt
                prompt = system_prompt + "\n\n" + user_prompt
                logger.info("Getting initial model response...")
            else:
                # Subsequent iterations: create continuation prompt
                prompt = self._create_continuation_prompt(
                    question, 
                    last_response, 
                    all_tool_results, 
                    image_paths,
                    all_additional_images,
                    iteration,
                    max_iterations
                )
                logger.info(f"Getting continuation response for iteration {iteration}...")
            
            if len(current_images) == 1:
                current_response = self.model.single_image_inference(
                    current_images[0], 
                    prompt,
                    **model_kwargs
                )
            else:
                current_response = self.model.multiple_images_inference(
                    current_images,
                    prompt,
                    **model_kwargs
                )
            
            logger.info(f"Response: {current_response}")
            
            # Save initial response
            if iteration == 1:
                initial_response = current_response
            last_response = current_response
            
            # Step 2: Parse tool calls from response
            tool_calls = self._parse_tool_calls(current_response)
            
            # Check if response has <answer> tags (indicating completion)
            has_answer = self._has_answer_tags(current_response)
            
            if not tool_calls:
                logger.info(f"No tool calls found in iteration {iteration}")
                if has_answer or iteration == max_iterations:
                    logger.info("Ending workflow: final answer provided or max iterations reached")
                    break
                # If no tool calls and no answer, continue to next iteration
                continue
            
            # Step 3: Execute tools
            logger.info(f"Executing {len(tool_calls)} tool calls in iteration {iteration}...")
            tool_results = self._execute_tools(tool_calls)
            
            # Step 4: Collect results
            iteration_additional_images = []
            for tool_name, result in tool_results.items():
                if result.get('success'):
                    all_successful_tools.append(f"{tool_name}_iter{iteration}")
                    # Collect additional images
                    if 'output_path' in result and result['output_path'] is not None:
                        if Path(result['output_path']).exists():
                            iteration_additional_images.append(result['output_path'])
                    if 'vis_path' in result and result['vis_path'] is not None:
                        if Path(result['vis_path']).exists():
                            iteration_additional_images.append(result['vis_path'])
            
            # Update tracking variables
            all_tool_calls.extend(tool_calls)
            all_tool_results.update({f"{k}_iter{iteration}": v for k, v in tool_results.items()})
            all_additional_images.extend(iteration_additional_images)
            
            # Update current images for next iteration
            if iteration_additional_images:
                # Use new images generated by tools
                valid_images = self._sort_additional_images_by_input_order(image_paths, iteration_additional_images)
                current_images = valid_images if valid_images else current_images
            
            # Check if we should stop (has answer tag and we're not forcing more iterations)
            if has_answer and iteration < max_iterations:
                logger.info(f"Answer provided in iteration {iteration}, but continuing workflow if more tool calls exist")
        
        # Generate final response if needed
        if not self._has_answer_tags(last_response) and all_successful_tools:
            logger.info("Generating final response...")
            tool_description = None
            if all_tool_results:
                last_result = list(all_tool_results.values())[-1]
                if last_result.get('description'):
                    tool_description = last_result.get('description')
            
            follow_up_prompt = create_follow_up_prompt(
                question, 
                initial_response, 
                all_tool_results,
                image_paths,
                all_additional_images,
                tool_description
            )
            
            valid_additional_images = self._sort_additional_images_by_input_order(image_paths, all_additional_images)
            final_images = valid_additional_images if valid_additional_images else image_paths
            
            if len(final_images) == 1:
                final_response = self.model.single_image_inference(
                    final_images[0],
                    follow_up_prompt,
                    **model_kwargs
                )
            else:
                final_response = self.model.multiple_images_inference(
                    final_images,
                    follow_up_prompt,
                    **model_kwargs
                )
        elif not self._has_answer_tags(last_response):
            # Generate fallback if no answer tags
            logger.warning("No answer tags found, generating fallback response")
            fallback_prompt = create_fallback_prompt(question, last_response)
            if len(current_images) == 1:
                final_response = self.model.single_image_inference(
                    current_images[0],
                    fallback_prompt,
                    **model_kwargs
                )
            else:
                final_response = self.model.multiple_images_inference(
                    current_images,
                    fallback_prompt,
                    **model_kwargs
                )
        else:
            final_response = last_response
        
        # Clean up temporary pi3 frames
        self._cleanup_pi3_frames()
        
        return {
            "answer": final_response,
            "initial_response": initial_response or final_response,
            "tool_calls": all_tool_calls,
            "tool_results": all_tool_results,
            "used_tools": all_successful_tools,
            "additional_images": all_additional_images,
            "iterations": iteration,
            "prompts": {
                "system_prompt": system_prompt,
                "user_prompt": user_prompt,
                "follow_up_prompt": None  # This is now handled in continuation prompts
            }
        }
    
    def _parse_tool_calls(self, response: str) -> List[Dict[str, Any]]:
        """
        Parse tool calls from model response
        
        Args:
            response: Model response text
            
        Returns:
            List of tool call dictionaries
        """
        tool_calls = []
        
        # Find all tool_call blocks
        pattern = r'<tool_call>\s*({.*?})\s*</tool_call>'
        matches = re.findall(pattern, response, re.DOTALL)
        
        for match in matches:
            try:
                tool_call = json.loads(match)
                if 'name' in tool_call and 'arguments' in tool_call:
                    tool_calls.append(tool_call)
                else:
                    logger.warning(f"Invalid tool call format: {match}")
            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse tool call JSON: {match}, error: {e}")
        
        return tool_calls
    
    def _execute_tools(self, tool_calls: List[Dict[str, Any]], video_path: Optional[str] = None, pi3_target_fps: float = 1.0) -> Dict[str, Any]:
        """
        Execute tool calls in parallel when possible
        
        Args:
            tool_calls: List of tool call dictionaries
            video_path: Optional path to original video (for pi3 tool re-sampling)
            pi3_target_fps: Target FPS for pi3 tool frame extraction
            
        Returns:
            Dictionary of tool_name -> result
        """
        tool_results = {}
        
        # Group tool calls by tool name to handle multiple calls to same tool
        tool_groups = {}
        for i, call in enumerate(tool_calls):
            tool_name = call['name']
            if tool_name not in tool_groups:
                tool_groups[tool_name] = []
            tool_groups[tool_name].append((i, call))
        
        # Execute tools in parallel, but Pi3Tool and Pi3MultiimgTool sequentially to avoid server issues
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            future_to_tool = {}
            
            # Handle Pi3Tool and Pi3MultiimgTool calls sequentially first
            pi3_calls = []
            other_calls = {}
            
            for tool_name, calls in tool_groups.items():
                if tool_name in ['pi3_tool', 'pi3_multiimg_tool']:
                    pi3_calls.extend(calls)
                else:
                    other_calls[tool_name] = calls
            
            # Execute Pi3Tool and Pi3MultiimgTool calls sequentially
            if pi3_calls:
                logger.info(f"Executing {len(pi3_calls)} Pi3 tool calls sequentially...")
                
                # Extract more frames for pi3 if video_path is provided
                pi3_frame_paths = []
                if video_path and Path(video_path).exists():
                    logger.info(f"Extracting frames for pi3 tool from video: {video_path} at {pi3_target_fps} fps")
                    pi3_frame_paths = self._extract_frames_for_pi3(video_path, pi3_target_fps)
                
                for call_idx, call in pi3_calls:
                    tool_name = call['name']
                    tool = self.tool_registry.get(tool_name)
                    if tool:
                        # If we extracted frames for pi3, update the arguments
                        arguments = call['arguments'].copy()
                        if pi3_frame_paths:
                            # Update image_path in arguments
                            if 'image_path' in arguments:
                                logger.info(f"Updating pi3 tool arguments with {len(pi3_frame_paths)} newly extracted frames")
                                arguments['image_path'] = pi3_frame_paths
                        
                        result = self._safe_tool_call(tool, arguments)
                        result_key = tool_name if len(pi3_calls) == 1 else f"{tool_name}_{call_idx}"
                        tool_results[result_key] = result
                        # Add small delay between Pi3 tool calls
                        import time
                        time.sleep(1)
                    else:
                        logger.error(f"{tool_name} not found")
                        result_key = tool_name if len(pi3_calls) == 1 else f"{tool_name}_{call_idx}"
                        tool_results[result_key] = {
                            "success": False,
                            "error": f"{tool_name} not found"
                        }
            
            # Execute other tools in parallel as before
            for tool_name, calls in other_calls.items():
                tool = self.tool_registry.get(tool_name)
                if tool is None:
                    logger.error(f"Tool not found: {tool_name}")
                    for _, call in calls:
                        tool_results[f"{tool_name}_{_}"] = {
                            "success": False,
                            "error": f"Tool not found: {tool_name}"
                        }
                    continue
                
                # Submit tool execution for each call
                for call_idx, call in calls:
                    future = executor.submit(self._safe_tool_call, tool, call['arguments'])
                    future_to_tool[future] = (tool_name, call_idx)
            
            # Collect results from parallel execution
            for future in as_completed(future_to_tool):
                tool_name, call_idx = future_to_tool[future]
                try:
                    result = future.result()
                    # Use unique key for multiple calls to same tool
                    result_key = tool_name if len([t for t in other_calls.get(tool_name, [])]) == 1 else f"{tool_name}_{call_idx}"
                    tool_results[result_key] = result
                except Exception as e:
                    logger.error(f"Tool execution failed for {tool_name}: {e}")
                    result_key = tool_name if len([t for t in other_calls.get(tool_name, [])]) == 1 else f"{tool_name}_{call_idx}"
                    tool_results[result_key] = {
                        "success": False,
                        "error": str(e)
                    }
        
        return tool_results
    
    def _safe_tool_call(self, tool: Tool, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """
        Safely execute a tool call with error handling
        
        Args:
            tool: Tool instance
            arguments: Tool arguments
            
        Returns:
            Tool execution result
        """
        try:
            logger.info(f"Executing tool: {tool.name} with args: {arguments}")
            result = tool.call(**arguments)
            logger.info(f"Tool {tool.name} completed successfully")
            return result
        except Exception as e:
            logger.error(f"Tool {tool.name} execution failed: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _sort_additional_images_by_input_order(self, image_paths: List[str], additional_images: List[str]) -> List[str]:
        """
        Sort additional images to match the order of input image_paths
        
        Args:
            image_paths: Original input image paths in order
            additional_images: Generated additional images (may be in different order)
            
        Returns:
            List of valid additional images sorted by input order
        """
        # Filter out None and invalid paths first
        valid_additional_images = [img for img in additional_images if img is not None and Path(img).exists()]
        
        if not valid_additional_images:
            return []
        
        # Create a sorted list of additional images based on input order
        sorted_additional_images = []
        
        for input_path in image_paths:
            input_stem = Path(input_path).stem
            
            # Find all additional images that correspond to this input image
            matching_images = []
            
            for additional_img in valid_additional_images:
                if additional_img in sorted_additional_images:
                    continue  # Already matched
                
                additional_stem = Path(additional_img).stem
                
                # Check if this additional image corresponds to the current input image
                if self._is_image_match(input_stem, additional_stem):
                    matching_images.append(additional_img)
            
            # Add matching images in a consistent order (by filename)
            matching_images.sort()
            sorted_additional_images.extend(matching_images)
        
        # Add any remaining unmatched additional images at the end
        for additional_img in valid_additional_images:
            if additional_img not in sorted_additional_images:
                sorted_additional_images.append(additional_img)
        
        logger.info(f"Sorted additional images: {[Path(img).name for img in sorted_additional_images]}")
        return sorted_additional_images
    
    def _is_image_match(self, input_stem: str, additional_stem: str) -> bool:
        """
        Check if an additional image corresponds to an input image
        
        Args:
            input_stem: Stem of input image filename
            additional_stem: Stem of additional image filename
            
        Returns:
            True if they match, False otherwise
        """
        # Since the suffix of saved images is always the same as the original image name,
        # we check if the additional image name ends with the input image name
        # This handles any prefix automatically without needing to maintain a list
        return additional_stem.endswith(input_stem)
    
    def _has_answer_tags(self, response: str) -> bool:
        """
        Check if response contains <answer> tags
        
        Args:
            response: Response text to check
            
        Returns:
            True if response contains <answer> tags, False otherwise
        """
        return '<answer>' in response and '</answer>' in response
    
    def _create_continuation_prompt(
        self, 
        question: str, 
        last_response: str, 
        all_tool_results: Dict[str, Any],
        original_images: List[str],
        additional_images: List[str],
        current_iteration: int,
        max_iterations: int
    ) -> str:
        """
        Create continuation prompt for multi-step workflow
        
        Args:
            question: Original user question
            last_response: Last model response
            all_tool_results: All tool results so far
            original_images: Original image paths
            additional_images: All additional images generated
            current_iteration: Current iteration number
            max_iterations: Maximum iterations allowed
            
        Returns:
            Continuation prompt string
        """
        tool_summary = []
        angle_info = []
        
        for tool_name, result in all_tool_results.items():
            if result.get('success'):
                tool_summary.append(f"- {tool_name}: Successfully executed")
                
                # Extract angle information if available
                if 'azimuth_angle' in result and 'elevation_angle' in result:
                    azim = result.get('azimuth_angle')
                    elev = result.get('elevation_angle')
                    angle_info.append(f"  └─ Viewing angle: azimuth={azim}°, elevation={elev}°")
                
                if result.get('description'):
                    tool_summary.append(f"  Description: {result.get('description')}")
            else:
                tool_summary.append(f"- {tool_name}: Failed - {result.get('error', 'Unknown error')}")
        
        tool_summary_text = "\n".join(tool_summary) if tool_summary else "None yet"
        angle_info_text = "\n".join(angle_info) if angle_info else ""
        
        additional_images_info = "\n".join([f"- {path}" for path in additional_images]) if additional_images else "None yet"
        
        remaining = max_iterations - current_iteration
        
        prompt = f"""=== Multi-Step Analysis: Iteration {current_iteration}/{max_iterations} ===

Original Question: {question}

Your Previous Response: 
{last_response}

Tool Execution Summary:
{tool_summary_text}
{angle_info_text}

Generated Images Available for Analysis:
{additional_images_info}

=== Next Steps ===

You have {remaining} more iteration(s) available. You can:

1. **Continue investigating** - Call tools with DIFFERENT parameters:
   - For Pi3 tools: Try different viewing angles to understand the 3D structure better
   - Example angles: front (0,0), left (-45,0), right (45,0), top (0,45), bottom (0,-45), back (180,0)
   - Each angle reveals different aspects of the 3D structure

2. **Provide final answer** - If you have sufficient information from current viewpoints:
   - Output your comprehensive analysis in <answer></answer> tags
   - Reference the specific viewpoints that helped you understand the structure

Instructions:
- Think: Do you need to see the object from another angle to answer the question better?
- If YES: Use <tool_call></tool_call> to request a different viewing angle
- If NO: Provide your final answer in <answer></answer>

Please continue:"""
        
        return prompt
    def _extract_frames_for_pi3(self, video_path: str, target_fps: float = 1.0) -> List[str]:
        """
        Extract frames from video for pi3 tool
        
        Args:
            video_path: Path to video file
            target_fps: Target frame rate
            
        Returns:
            List of paths to extracted frame images
        """
        try:
            import cv2
            import numpy as np
        except ImportError:
            logger.error("cv2 is required for video frame extraction. Please install opencv-python.")
            return []
        
        cap = cv2.VideoCapture(video_path)
        
        # Get video info
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        original_fps = cap.get(cv2.CAP_PROP_FPS)
        total_duration = total_frames / original_fps
        
        # Calculate frames to extract based on target fps
        num_frames = int(total_duration * target_fps)
        frame_interval = total_frames / num_frames
        
        frame_paths = []
        temp_dir = Path("temp_frames_pi3")
        temp_dir.mkdir(exist_ok=True)
        
        # Extract video filename (without extension)
        video_filename = Path(video_path).stem
        
        # Extract frames evenly
        for i in range(num_frames):
            frame_idx = int(i * frame_interval)
            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
            ret, frame = cap.read()
            if ret:
                frame_path = temp_dir / f"{video_filename}_pi3_frame_{i}.jpg"
                cv2.imwrite(str(frame_path), frame)
                frame_paths.append(str(frame_path))
        
        cap.release()
        logger.info(f"Extracted {len(frame_paths)} frames from video for pi3 tool (duration: {total_duration:.2f}s, original fps: {original_fps:.2f}, target fps: {target_fps})")
        return frame_paths
    
    def _cleanup_pi3_frames(self):
        """
        Clean up temporary frames extracted for pi3 tool
        """
        import os
        import shutil
        
        temp_dir = Path("temp_frames_pi3")
        if temp_dir.exists():
            try:
                shutil.rmtree(temp_dir)
                logger.info("Cleaned up temporary pi3 frames")
            except Exception as e:
                logger.warning(f"Failed to clean up temporary pi3 frames: {e}")
