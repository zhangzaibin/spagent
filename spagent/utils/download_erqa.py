#!/usr/bin/env python3
"""
ä½¿ç”¨PyTorchç¯å¢ƒè¯»å–TFRecordæ–‡ä»¶å¹¶è½¬æ¢ä¸ºå¯¹è¯æ ¼å¼çš„JSON
ä¸ä¾èµ–TensorFlowï¼Œä½¿ç”¨tfrecordåº“
"""

import torch
import tfrecord  # çº¯Pythonåº“ç”¨äºè¯»å–TFRecordæ–‡ä»¶
import json
import os
from PIL import Image
import io

output_jsonl_path = 'dataset/ERQA_data.jsonl'
images_dir = 'dataset/ERQA_images'

def convert_erqa_to_conversations():
    """å°†ERQAæ•°æ®é›†è½¬æ¢ä¸ºå¯¹è¯æ ¼å¼çš„JSONLæ–‡ä»¶ï¼Œå¹¶ä¿å­˜å›¾ç‰‡"""
    
    # è·¯å¾„é…ç½®
    tfrecord_path = 'dataset/ERQA/erqa.tfrecord'

    # åˆ›å»ºå›¾ç‰‡ç›®å½•
    os.makedirs(images_dir, exist_ok=True)
    
    print("ğŸš€ ERQAæ•°æ®é›†è½¬æ¢å·¥å…· (PyTorchç‰ˆæœ¬)")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"è®¾å¤‡: {'CUDA' if torch.cuda.is_available() else 'CPU'}")
    print("=" * 60)
    print(f"è¾“å…¥æ–‡ä»¶: {tfrecord_path}")
    print(f"è¾“å‡ºJSONL: {output_jsonl_path}")
    print(f"å›¾ç‰‡ç›®å½•: {images_dir}")
    print("=" * 60)
    
    # ä½¿ç”¨tfrecordåº“åŠ è½½æ•°æ®é›†
    dataset = tfrecord.tfrecord_loader(tfrecord_path, None)
    
    total_examples = 0
    total_images_saved = 0
    
    print("æ­£åœ¨å¤„ç†æ•°æ®...")
    
    # æ‰“å¼€JSONLæ–‡ä»¶ç”¨äºå†™å…¥
    with open(output_jsonl_path, 'w', encoding='utf-8') as jsonl_file:
        for i, example in enumerate(dataset):
            total_examples += 1
            
            try:
                # æå–å’Œè§£ç æ•°æ®
                question = example['question'].decode('utf-8') if isinstance(example['question'], bytes) else str(example['question'])
                answer = example['answer'].decode('utf-8') if isinstance(example['answer'], bytes) else str(example['answer'])
                
                # å¤„ç†question_type
                question_type_raw = example['question_type']
                if isinstance(question_type_raw, bytes):
                    question_type = question_type_raw.decode('utf-8')
                elif hasattr(question_type_raw, '__len__') and len(question_type_raw) > 0:
                    if isinstance(question_type_raw[0], bytes):
                        question_type = question_type_raw[0].decode('utf-8')
                    else:
                        question_type = str(question_type_raw[0])
                else:
                    question_type = "Unknown"
                
                # å¤„ç†visual_indices
                visual_indices = example['visual_indices']
                if hasattr(visual_indices, 'tolist'):
                    visual_indices = visual_indices.tolist()
                elif not isinstance(visual_indices, list):
                    visual_indices = [visual_indices] if visual_indices is not None else []
                
                # å¤„ç†å›¾åƒæ•°æ®
                image_data = example['image/encoded']
                image_paths = []
                
                # å¤„ç†å•å¼ å›¾ç‰‡çš„æƒ…å†µ (bytesç±»å‹)
                if isinstance(image_data, bytes):
                    try:
                        # ä¿å­˜å›¾ç‰‡
                        img = Image.open(io.BytesIO(image_data))
                        
                        # ç”Ÿæˆæ–‡ä»¶å
                        filename = f"ERQA_{i:04d}.jpg"
                        filepath = os.path.join(images_dir, filename)
                        relative_path = f"ERQA_images/{filename}"

                        # ä¿å­˜å›¾ç‰‡
                        img.save(filepath, 'JPEG')
                        img.close()
                        
                        image_paths.append(relative_path)
                        total_images_saved += 1
                        
                    except Exception as e:
                        print(f"è­¦å‘Š: ä¿å­˜å›¾ç‰‡å¤±è´¥ (ç¤ºä¾‹ {i+1}): {e}")
                
                # å¤„ç†å¤šå¼ å›¾ç‰‡çš„æƒ…å†µ (numpyæ•°ç»„æˆ–åˆ—è¡¨)
                elif hasattr(image_data, '__len__') and len(image_data) > 0:
                    for j in range(len(image_data)):
                        img_bytes = image_data[j]
                        
                        # ç¡®ä¿æ˜¯bytesæ ¼å¼
                        if isinstance(img_bytes, bytes):
                            try:
                                img = Image.open(io.BytesIO(img_bytes))
                                
                                filename = f"ERQA_{i:04d}_image_{j}.jpg"
                                filepath = os.path.join(images_dir, filename)
                                relative_path = f"ERQA_images/{filename}"
                                
                                img.save(filepath, 'JPEG')
                                img.close()
                                
                                image_paths.append(relative_path)
                                total_images_saved += 1
                                
                            except Exception as e:
                                print(f"è­¦å‘Š: ä¿å­˜å›¾ç‰‡ {j} å¤±è´¥ (ç¤ºä¾‹ {i+1}): {e}")
                        else:
                            print(f"è­¦å‘Š: ç¤ºä¾‹ {i+1} å›¾ç‰‡ {j} ä¸æ˜¯bytesæ ¼å¼: {type(img_bytes)}")
                
                else:
                    print(f"è­¦å‘Š: ç¤ºä¾‹ {i+1} æ²¡æœ‰æœ‰æ•ˆçš„å›¾åƒæ•°æ®")
                
                # æ„å»ºå¯¹è¯æ ¼å¼çš„æ•°æ®
                conversation_entry = {
                    "id": f"erqa_{i:04d}",
                    "image": image_paths, 
                    "video": [],
                    "conversations": [
                        {
                            "from": "human",
                            "value": question
                        },
                        {
                            "from": "gpt", 
                            "value": answer
                        }
                    ],
                    "task": question_type,
                    "input_type": "Image", 
                    "output_type": "MCQ", 
                    "data_source": "ERQA", 
                    "others": {"visual_indices": visual_indices},
                }
                
                # å†™å…¥JSONLæ–‡ä»¶ï¼ˆæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰
                jsonl_file.write(json.dumps(conversation_entry, ensure_ascii=False) + '\n')
                
                # æ˜¾ç¤ºè¿›åº¦
                if (i + 1) % 50 == 0:
                    print(f"å·²å¤„ç† {i + 1} ä¸ªç¤ºä¾‹ï¼Œä¿å­˜äº† {total_images_saved} å¼ å›¾ç‰‡...")
                    
            except Exception as e:
                print(f"é”™è¯¯: å¤„ç†ç¤ºä¾‹ {i+1} æ—¶å‡ºé”™: {e}")
                continue
    
    print(f"\nâœ… è½¬æ¢å®Œæˆï¼")
    print(f"æ€»å…±å¤„ç†äº† {total_examples} ä¸ªç¤ºä¾‹")
    print(f"æˆåŠŸä¿å­˜äº† {total_images_saved} å¼ å›¾ç‰‡")
    print(f"è¾“å‡ºJSONLæ–‡ä»¶: {output_jsonl_path}")
    print(f"å›¾ç‰‡ç›®å½•: {images_dir}")

def verify_conversion():
    """éªŒè¯è½¬æ¢ç»“æœ"""    
    print(f"\nğŸ” éªŒè¯è½¬æ¢ç»“æœ...")
    print("=" * 60)
    data = []
    try:
        # æ£€æŸ¥JSONæ–‡ä»¶
        with open(output_jsonl_path, "r", encoding="utf-8") as f:
            for line in f:
                if line.strip():  # è·³è¿‡ç©ºè¡Œ
                    data.append(json.loads(line))

        
        print(f"JSONæ–‡ä»¶æ¡ç›®æ•°: {len(data)}")
        
        # æ˜¾ç¤ºå‰3ä¸ªç¤ºä¾‹
        for i in range(min(3, len(data))):
            entry = data[i]
            print(f"\nç¤ºä¾‹ {i+1}:")
            print(f"  ID: {entry['id']}")
            print(f"  é—®é¢˜ç±»å‹: {entry['task']}")
            print(f"  å¯¹è¯æ¡æ•°: {len(entry['conversations'])}")
            print(f"  Human: {entry['conversations'][0]['value'][:100]}...")
            print(f"  GPT: {entry['conversations'][1]['value']}")
            print(f"  å›¾ç‰‡æ•°é‡: {len(entry['image'])}")
            print(f"  å›¾ç‰‡è·¯å¾„: {entry['image']}")
            print(f"  è§†è§‰ç´¢å¼•: {entry['others'].get('visual_indices', [])}")
            
            # éªŒè¯å›¾ç‰‡æ–‡ä»¶
            for img_path in entry['image']:
                full_path = f"./data/{img_path}"
                exists = os.path.exists(full_path)
                print(f"    å›¾ç‰‡æ–‡ä»¶ {img_path}: {'å­˜åœ¨' if exists else 'ä¸å­˜åœ¨'}")
        
        # æ£€æŸ¥å›¾ç‰‡ç›®å½•
        if os.path.exists(images_dir):
            image_files = os.listdir(images_dir)
            print(f"\nå›¾ç‰‡ç›®å½•ä¸­çš„æ–‡ä»¶æ•°é‡: {len(image_files)}")
            print(f"ç¤ºä¾‹å›¾ç‰‡æ–‡ä»¶: {image_files[:5]}")
        
        print(f"\nâœ… éªŒè¯å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")

def show_statistics():
    """æ˜¾ç¤ºæ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
    print(f"\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯:")
    print("=" * 60)
    
    try:
        data = []
        with open(output_jsonl_path, "r", encoding="utf-8") as f:
            for line in f:
                if line.strip():  # è·³è¿‡ç©ºè¡Œ
                    data.append(json.loads(line))
        
        # åŸºæœ¬ç»Ÿè®¡
        print(f"æ€»ç¤ºä¾‹æ•°: {len(data)}")
        
        # é—®é¢˜ç±»å‹ç»Ÿè®¡
        question_types = {}
        image_counts = {}
        
        for item in data:
            q_type = item['task']
            question_types[q_type] = question_types.get(q_type, 0) + 1
            
            img_count = len(item['image'])
            image_counts[img_count] = image_counts.get(img_count, 0) + 1
        
        print(f"\né—®é¢˜ç±»å‹åˆ†å¸ƒ:")
        for q_type, count in sorted(question_types.items(), key=lambda x: x[1], reverse=True)[:10]:
            print(f"  {q_type}: {count}")
        
        print(f"\nå›¾ç‰‡æ•°é‡åˆ†å¸ƒ:")
        for img_count, count in sorted(image_counts.items()):
            print(f"  {img_count} å¼ å›¾ç‰‡: {count} ä¸ªç¤ºä¾‹")
        
    except Exception as e:
        print(f"âŒ ç»Ÿè®¡ä¿¡æ¯ç”Ÿæˆå¤±è´¥: {e}")

if __name__ == "__main__":
    print("ğŸ”¥ ä½¿ç”¨PyTorchç¯å¢ƒè½¬æ¢ERQAæ•°æ®é›†")
    print("è½¬æ¢ä¸ºå¯¹è¯æ ¼å¼å¹¶ä¿å­˜å›¾ç‰‡")
    print("=" * 60)
    
    # æ‰§è¡Œè½¬æ¢
    convert_erqa_to_conversations()
    
    # éªŒè¯ç»“æœ
    verify_conversion()
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    show_statistics()
    